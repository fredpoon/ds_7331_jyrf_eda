{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "# from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_master = pd.read_csv('PublicSchools2014to2017_YZ.csv')\n",
    "\n",
    "df_headers = ['TotalTargets_pTarget_PctMet',\n",
    "    # 'EVAAS Growth Status_NotMet',\n",
    "    'MinorityMalePct',\n",
    "    'MinorityFemalePct',\n",
    "    # 'title1_type_cd_Y',\n",
    "    'avg_daily_attend_pct',\n",
    "    'short_susp_per_c_num',\n",
    "    'BlackMalePct',\n",
    "    'AsianFemalePct',\n",
    "    'student_num',\n",
    "    'HispanicMalePct',\n",
    "    'SciGr5&8_pTarget_PctMet',\n",
    "    'tchyrs_0thru3_pct',\n",
    "    'tchyrs_11plus_pct',\n",
    "    'Accomplished_TCHR_Standard 2_Pct',\n",
    "    'Accomplished_TCHR_Standard 1_Pct',\n",
    "    'Developing_TCHR_Standard 1_Pct',\n",
    "    'Developing_TCHR_Standard 2_Pct',\n",
    "    'Developing_TCHR_Standard 3_Pct',\n",
    "    'Accomplished_TCHR_Standard 4_Pct',\n",
    "    '4-10 Years_LEA_Exp_Pct_Prin',\n",
    "    'Developing_TCHR_Standard 4_Pct',\n",
    "    'Developing_TCHR_Standard 5_Pct',\n",
    "    '10+ Years_LEA_Exp_Pct_Prin',\n",
    "    'Accomplished_TCHR_Standard 3_Pct',\n",
    "    'Accomplished_TCHR_Standard 5_Pct',\n",
    "    'lea_state_perpupil_num',\n",
    "    'st_emer_prov_teach_pct',\n",
    "    'pct_GCE_ALL',\n",
    "    'MathGr3-8_pTarget_PctMet',\n",
    "    'lea_sat_avg_score_num',\n",
    "    'lea_federal_perpupil_num',\n",
    "    'lea_local_perpupil_num',\n",
    "    'nbpts_num',\n",
    "    'Distinguished_TCHR_Standard 2_Pct',\n",
    "    '_1yr_tchr_trnovr_pct',\n",
    "    'lateral_teach_pct',\n",
    "    '0-3 Years_LEA_Exp_Pct_Prin',\n",
    "    'lea_flicensed_teach_pct',\n",
    "    'lea_tchyrs_4thru10_pct',\n",
    "    'lea_tchyrs_11plus_pct',\n",
    "    'lea_nbpts_num',\n",
    "    'lea_advance_dgr_pct',\n",
    "    'lea_1yr_tchr_trnovr_pct',\n",
    "    'lea_emer_prov_teach_pct',\n",
    "    'st_flicensed_teach_pct',\n",
    "    'st_tchyrs_0thru3_pct',\n",
    "    'st_1yr_tchr_trnovr_pct',\n",
    "    'lea_tchyrs_0thru3_pct',\n",
    "    # 'Category_Cd_T'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "<class 'pandas.core.frame.DataFrame'>\nInt64Index: 8675 entries, 0 to 9730\nColumns: 262 entries, vphone_ad to Majority_Minority\ndtypes: float64(238), int32(1), int64(2), object(21)\nmemory usage: 17.4+ MB\n"
    }
   ],
   "source": [
    "# data clean up\n",
    "\n",
    "# schools2['category_cd'].unique()\n",
    "df_master['category_cd_modified'] = np.select(\n",
    "    [\n",
    "        df_master['category_cd'] == 'A', \n",
    "        df_master['category_cd'] == 'E',\n",
    "        df_master['category_cd'] == 'H',\n",
    "        df_master['category_cd'] == 'I',\n",
    "        df_master['category_cd'] == 'M'\n",
    "    ], \n",
    "    [\n",
    "        'Elem./Mid./High Together', \n",
    "        'Elementary School',\n",
    "        'High School',\n",
    "        'Elem./Mid. Together',\n",
    "        'Middle School'\n",
    "    ],\n",
    "    default='Mid./High Together'\n",
    ")\n",
    "\n",
    "combo = df_master['category_cd_modified'].str.contains('/', regex=False)\n",
    "\n",
    "df_master['category_cd_modified'] = np.where(combo, 'Combo', df_master['category_cd_modified'])\n",
    "\n",
    "df_master['MinorityOverallPct'] = df_master['MinorityMalePct'] + df_master['MinorityFemalePct']\n",
    "\n",
    "df_master['Majority_Minority'] = np.where(df_master['MinorityOverallPct'] > .5, 1,0)\n",
    "\n",
    "df_final = df_master[df_master[\"school_type_txt\"] == 'Regular School']\n",
    "\n",
    "\n",
    "combo = df_final['SPG Grade'].str.contains('A+NG', regex=False)\n",
    "\n",
    "df_final['SPG Grade'] = np.where(combo, 'A', df_final['SPG Grade'])\n",
    "\n",
    "# df_final['SPG Grade'].value_counts()\n",
    "\n",
    "df_final = df_final[df_final['SPG Grade'] != 'I']\n",
    "\n",
    "df_final['SPG Grade'].value_counts()\n",
    "\n",
    "df_master = df_final\n",
    "\n",
    "df_master.info()\n",
    "\n",
    "# pd.DataFrame(df_master[\"school_type_txt\"].unique())\n",
    "\n",
    "# pd.DataFrame(df_master['Majority_Minority'].value_counts())\n",
    "\n",
    "# pd.DataFrame(df_master.category_cd_modified.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "ShuffleSplit(n_splits=3, random_state=None, test_size=0.2, train_size=None)\n"
    }
   ],
   "source": [
    "if 'SPG Score' in df_master:\n",
    "    y = df_master['SPG Grade'].values\n",
    "    X = df_master[df_headers].values\n",
    "\n",
    "num_cv_iterations = 3\n",
    "num_instances = len(y)\n",
    "cv_object = ShuffleSplit(n_splits=num_cv_iterations,\n",
    "                        test_size= 0.2)\n",
    "\n",
    "print(cv_object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for train_indices, test_indices in cv_object.split(X,y):\n",
    "    \n",
    "    X_train = X[train_indices]\n",
    "    y_train = y[train_indices]\n",
    "    \n",
    "    X_test = X[test_indices]\n",
    "    y_test = y[test_indices]\n",
    "\n",
    "# StandardScaler\n",
    "scl_obj = StandardScaler()\n",
    "scl_obj.fit(X_train)\n",
    "\n",
    "X_train_scaled = scl_obj.transform(X_train)\n",
    "X_test_scaled = scl_obj.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.652449567723343"
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "model = LogisticRegression()\n",
    "\n",
    "model.fit(X_train_scaled, y_train)\n",
    "pred = model.predict(X_test_scaled)\n",
    "\n",
    "accuracy_score(y_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.624207492795389"
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "#Lasso\n",
    "model2 = LogisticRegression(penalty='l1', solver='liblinear')\n",
    "\n",
    "model2.fit(X_train_scaled, y_train)\n",
    "pred = model2.predict(X_test_scaled)\n",
    "\n",
    "accuracy_score(y_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n[CV] C=0.1, penalty=l1, solver=liblinear .............................\n[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n[CV] .............. C=0.1, penalty=l1, solver=liblinear, total=   0.3s\n[CV] C=0.1, penalty=l1, solver=liblinear .............................\n[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.2s remaining:    0.0s\n[CV] .............. C=0.1, penalty=l1, solver=liblinear, total=   0.3s\n[CV] C=0.1, penalty=l1, solver=liblinear .............................\n[CV] .............. C=0.1, penalty=l1, solver=liblinear, total=   0.3s\n[CV] C=0.1, penalty=l1, solver=liblinear .............................\n[CV] .............. C=0.1, penalty=l1, solver=liblinear, total=   0.3s\n[CV] C=0.1, penalty=l1, solver=liblinear .............................\n[CV] .............. C=0.1, penalty=l1, solver=liblinear, total=   0.4s\n[CV] C=0.1, penalty=l2, solver=liblinear .............................\n[CV] .............. C=0.1, penalty=l2, solver=liblinear, total=   0.3s\n[CV] C=0.1, penalty=l2, solver=liblinear .............................\n[CV] .............. C=0.1, penalty=l2, solver=liblinear, total=   0.3s\n[CV] C=0.1, penalty=l2, solver=liblinear .............................\n[CV] .............. C=0.1, penalty=l2, solver=liblinear, total=   0.3s\n[CV] C=0.1, penalty=l2, solver=liblinear .............................\n[CV] .............. C=0.1, penalty=l2, solver=liblinear, total=   0.3s\n[CV] C=0.1, penalty=l2, solver=liblinear .............................\n[CV] .............. C=0.1, penalty=l2, solver=liblinear, total=   0.3s\n[CV] C=10, penalty=l1, solver=liblinear ..............................\n[CV] ............... C=10, penalty=l1, solver=liblinear, total=   2.0s\n[CV] C=10, penalty=l1, solver=liblinear ..............................\n[CV] ............... C=10, penalty=l1, solver=liblinear, total=   1.0s\n[CV] C=10, penalty=l1, solver=liblinear ..............................\n[CV] ............... C=10, penalty=l1, solver=liblinear, total=   1.4s\n[CV] C=10, penalty=l1, solver=liblinear ..............................\n[CV] ............... C=10, penalty=l1, solver=liblinear, total=   1.5s\n[CV] C=10, penalty=l1, solver=liblinear ..............................\n[CV] ............... C=10, penalty=l1, solver=liblinear, total=   1.5s\n[CV] C=10, penalty=l2, solver=liblinear ..............................\n[CV] ............... C=10, penalty=l2, solver=liblinear, total=   0.5s\n[CV] C=10, penalty=l2, solver=liblinear ..............................\n[CV] ............... C=10, penalty=l2, solver=liblinear, total=   0.5s\n[CV] C=10, penalty=l2, solver=liblinear ..............................\n[CV] ............... C=10, penalty=l2, solver=liblinear, total=   0.5s\n[CV] C=10, penalty=l2, solver=liblinear ..............................\n[CV] ............... C=10, penalty=l2, solver=liblinear, total=   0.5s\n[CV] C=10, penalty=l2, solver=liblinear ..............................\n[CV] ............... C=10, penalty=l2, solver=liblinear, total=   0.5s\n[CV] C=100, penalty=l1, solver=liblinear .............................\n[CV] .............. C=100, penalty=l1, solver=liblinear, total=  50.4s\n[CV] C=100, penalty=l1, solver=liblinear .............................\n[CV] .............. C=100, penalty=l1, solver=liblinear, total=  49.0s\n[CV] C=100, penalty=l1, solver=liblinear .............................\n[CV] .............. C=100, penalty=l1, solver=liblinear, total=  55.2s\n[CV] C=100, penalty=l1, solver=liblinear .............................\n[CV] .............. C=100, penalty=l1, solver=liblinear, total=  38.7s\n[CV] C=100, penalty=l1, solver=liblinear .............................\n[CV] .............. C=100, penalty=l1, solver=liblinear, total=  50.7s\n[CV] C=100, penalty=l2, solver=liblinear .............................\n[CV] .............. C=100, penalty=l2, solver=liblinear, total=   0.7s\n[CV] C=100, penalty=l2, solver=liblinear .............................\n[CV] .............. C=100, penalty=l2, solver=liblinear, total=   0.7s\n[CV] C=100, penalty=l2, solver=liblinear .............................\n[CV] .............. C=100, penalty=l2, solver=liblinear, total=   0.7s\n[CV] C=100, penalty=l2, solver=liblinear .............................\n[CV] .............. C=100, penalty=l2, solver=liblinear, total=   0.6s\n[CV] C=100, penalty=l2, solver=liblinear .............................\n[CV] .............. C=100, penalty=l2, solver=liblinear, total=   0.8s\n[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:  4.3min finished\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "GridSearchCV(cv=None, error_score=nan,\n             estimator=LogisticRegression(C=1.0, class_weight=None, dual=False,\n                                          fit_intercept=True,\n                                          intercept_scaling=1, l1_ratio=None,\n                                          max_iter=100, multi_class='auto',\n                                          n_jobs=None, penalty='l2',\n                                          random_state=None, solver='lbfgs',\n                                          tol=0.0001, verbose=0,\n                                          warm_start=False),\n             iid='deprecated', n_jobs=None,\n             param_grid={'C': [0.1, 10, 100], 'penalty': ['l1', 'l2'],\n                         'solver': ['liblinear']},\n             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n             scoring=None, verbose=2)"
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "# from sklearn.pipeline import Pipeline\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# from sklearn.feature_selection import \n",
    "\n",
    "# pipe = Pipeline([RandomForestClassifier(n_estimators=)])\n",
    "\n",
    "param_grid = {'C': [0.1, 10, 100], 'penalty': ['l1','l2'], 'solver': ['liblinear']}\n",
    " \n",
    "\n",
    "grid = GridSearchCV(LogisticRegression(), param_grid, refit=True, verbose=2)\n",
    "grid.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "{'C': 100, 'penalty': 'l1', 'solver': 'liblinear'}\n"
    }
   ],
   "source": [
    "print(grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[[ 47  45   6   1   0]\n [ 13 209 210   4   0]\n [  1  72 636  69   0]\n [  0   2 154 173   5]\n [  0   0   6  66  16]]\n              precision    recall  f1-score   support\n\n           A       0.77      0.47      0.59        99\n           B       0.64      0.48      0.55       436\n           C       0.63      0.82      0.71       778\n           D       0.55      0.52      0.53       334\n           F       0.76      0.18      0.29        88\n\n    accuracy                           0.62      1735\n   macro avg       0.67      0.49      0.53      1735\nweighted avg       0.63      0.62      0.61      1735\n\n"
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "grid_predictions = grid.predict(X_test_scaled)\n",
    "print(confusion_matrix(y_test, grid_predictions))\n",
    "print(classification_report(y_test, grid_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "AttributeError",
     "evalue": "'SMOTE' object has no attribute '_validate_data'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-5169af93fe28>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mimblearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mover_sampling\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSMOTE\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mX_train_resampled\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train_resampled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSMOTE\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_resample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_scaled\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mgrid\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_resampled\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train_resampled\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\ML1_Sumr2020\\lib\\site-packages\\imblearn\\base.py\u001b[0m in \u001b[0;36mfit_resample\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m     75\u001b[0m         \u001b[0mcheck_classification_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m         \u001b[0marrays_transformer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mArraysTransformer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 77\u001b[1;33m         \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbinarize_y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_X_y\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     78\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m         self.sampling_strategy_ = check_sampling_strategy(\n",
      "\u001b[1;32m~\\anaconda3\\envs\\ML1_Sumr2020\\lib\\site-packages\\imblearn\\base.py\u001b[0m in \u001b[0;36m_check_X_y\u001b[1;34m(self, X, y, accept_sparse)\u001b[0m\n\u001b[0;32m    132\u001b[0m             \u001b[0maccept_sparse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m\"csr\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"csc\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m         \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbinarize_y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_target_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindicate_one_vs_all\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 134\u001b[1;33m         X, y = self._validate_data(\n\u001b[0m\u001b[0;32m    135\u001b[0m             \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maccept_sparse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    136\u001b[0m         )\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'SMOTE' object has no attribute '_validate_data'"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "X_train_resampled, y_train_resampled = SMOTE().fit_resample(X_train_scaled,y_train)\n",
    "\n",
    "grid.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "grid_predictions2 = grid.predict(X_test)\n",
    "\n",
    "pred_compare3 = pd.DataFrame({'preds': grid_predictions2, 'actual': y_test})[['preds', 'actual']]\n",
    "\n",
    "acc = mt.accuracy_score(y_test, grid_predictions2)\n",
    "\n",
    "print(acc)\n",
    "\n",
    "pd.crosstab(pred_compare3['preds'], pred_compare3['actual'])"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37164bitml1sumr2020condaf1b124117553466b89d65eb9c9f3513c",
   "display_name": "Python 3.7.1 64-bit ('ML1_Sumr2020': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}