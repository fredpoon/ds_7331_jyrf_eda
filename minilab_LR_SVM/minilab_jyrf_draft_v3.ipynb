{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Category \tAvailable \tRequirements\n",
    "Total Points \t100\t\n",
    "Create Models\t50\tCreate a logistic regression model and a support vector machine model for the classification task involved with your dataset. Assess how well each model performs (use 80/20 training/testing split for your data). Adjust parameters of the models to make them more accurate. If your dataset size requires the use of stochastic gradient descent, then linear kernel only is fine to use. That is, the SGDClassifier is fine to use for optimizing logistic regression and linear support vector machines. For many problems, SGD will be required in order to train the SVM model in a reasonable timeframe. \n",
    "Model Advantages\t10\tDiscuss the advantages of each model for each classification task. Does one type of model offer superior performance over another in terms of prediction accuracy? In terms of training time or efficiency? Explain in detail.\n",
    "Interpret Feature Importance\t30\tUse the weights from logistic regression to interpret the importance of different features for the classification task. Explain your interpretation in detail. Why do you think some variables are more important?\n",
    "Interpret Support Vectors\t10\tLook at the chosen support vectors for the classification task. Do these provide any insight into the data? Explain. If you used stochastic gradient descent (and therefore did not explicitly solve for support vectors), try subsampling your data to train the SVC model— then analyze the support vectors from the subsampled dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. You must include all of your data wrangling code, if you want to receive full credit.  Otherwise, your work is not reproducible.  This is true for all submissions. You are the only group who left this out. I need to see what you started with and all transformations. The dataset must still meet the minimum size after all transformations.  I will not accept future labs without this code included.  \n",
    "\n",
    "2. I have stated multiple times that the minimum dataset size is 15 columns x 30,000 rows = 450,000 elements. My feedback clearly states that what you submitted is currently at 16 * 9731 = 155,696 elements. As I said in the feedback: \"In future labs, you will need to increase the number of fields you use for modeling to achieve at least 15 * 30,000 = 450,000 elements.\". \n",
    "\n",
    "3. Unfortunately for Lab 1, it really makes no difference what your yearly tables may look like at this point, because they were not included in your submission? \n",
    "\n",
    "4. I see above that the dataset you produced for each year has many more fields / columns / features that you could have included to meet the minimum size requirements?  The starting point should have likely been that entire dataset.  I am also slightly concerned about your statement that \"merging is a simple inner join activity\" for a number of reasons. The dataset you started with does not appear to be joined at all.  There is a year column in the dataset.  This gives me the impression that you actually unioned the data by year (which is what I would have expected). However, I really have no clue what you did, because you chose not to share that with me.\n",
    "\n",
    "Thoughts on inner joining this data:\n",
    "A number of public school campuses open and close each school year.  If you are joining by unit_code / agency_code, your analysis will only include school campuses open during the entire duration of the data.\n",
    "Any classification model you create in a \"joined\" dataset will likely have duplicated columns for each year.  This means that the feature importances for the model will be dominated by prior years.  For example, if you build a model to predict graduation rates, the model will use all prior year's graduation rates for the prediction.  It will also be very accurate.  However, I am not sure what benefit such a model would provide to the public school system?\n",
    "Typically, you would not include any graduation rate features in your graduation rate model training data at all. (we can talk about this more, if needed).      \n",
    "\n",
    "##### CRISP-DM (Cross Industry standard process for data mining)\n",
    "- Business Understanding\n",
    "- Data Understanding\n",
    "- Data Preparation\n",
    "- Modeling\n",
    "- Evaluation\n",
    "- Deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MiniLab SVM and Logistic Regression\n",
    "#### 06/14/2020\n",
    "#### Yang Zhang, Reannan McDaniel, Jonathon Roach, Fred Poon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Business Understanding\n",
    "For this analysis, our group will be working with North Carolina Public Schools Report Card and Statistical Profiles Data sets from the years 2014 to 2017. These data sets encompass information across 4 continuous years of educational attributes in North Carolina, USA.  The data is collected from the State of North Carolina at [http://ncpublicschools.org](http://ncpublicschools.org) and made available from the Belk Endowment Educational Attainment Data Repository for North Carolina Public Schools by Dr. Jake Drew. Among other reasons, the data was collected for evaluation of public-school performance for the purpose of efficiently allocating funds to various educational initiatives. Analyses of such data are important because high-impact educational initiatives that are well-funded contribute to increased graduation rates, increased achievement at the post-secondary level, less crime, and greater economic engagement among young people. For the purpose of this exercise, our focus is on describing and predicting school performance using various school characteristics, such as type of school (elementary, middle, high, or some combination of the three), social demographics, economic demographics, and location between 2014 and 2017. The Belk Foundation's website says, \"Our goal is to empower today’s workforce by creating pathways to and through postsecondary education for underrepresented students\". \n",
    "\n",
    "<!-- For the sake of this analysis, we assume that better performing schools have better outcomes in postsecondary education. With North Carolina's rapidly changing demographics, it is important to take into consideration schools' unique needs when allocating funds to strategic investment initiatives. Here, we explore where funding can be best applied based on educational achievement data.-->\n",
    "\n",
    "We will explore through visual and mathematical modeling which features best predict the School Performance Grade (SPG Grade), a letter grade classification based on test scores and growth measures. The analysis will come in the form of logistic regression model and support vector machine(SVM) model to classify SPG Grade. In this analysis we will observe:\n",
    "\n",
    "- What attributes have the most effect on SPG?\n",
    "- Between SVM and Logistic Regression, which model has a higher accuracy score?\n",
    "\n",
    "<!-- Predicting SPG within 15 points could be beneficial to an organization, like Belk Endowment, to efficiently allocate funds to schools.-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Understanding\n",
    "### Data Meaning Type\n",
    "\n",
    "The data set contains 9,731 records and 259 attributes that are comprised of factors, numbers, and characters. A data definition sheet can be found in Dr. Drew's github repository, [https://github.com/jakemdrew/EducationDataNC](https://github.com/jakemdrew/EducationDataNC/tree/master/Data%20Documentation). To scale the data to be more manageable, our data set includes 50 of the 259 attributes. \n",
    "\n",
    "These variables were chosen after initial EDA and correlation visuals were generated between SPG and all predictors. The data type, category and description are displayed in the following table.\n",
    "\n",
    "\n",
    "# TODO Update Attributes\n",
    "### Attributes\n",
    "| Attribute | DataType | Description |\n",
    "|:---|:---|:---|\n",
    "| SPG Score | float64 | School Performance Grade (number, 0-100) |\n",
    "| SPG Grade | object | School Performance Grade (Letter Grade - A-D, F) |\n",
    "| avg_daily_attend_pct | float64 | Average daily attendance percentage (0.8-1.0) |\n",
    "| category_cd | object | Category Code of the school level E=Elementary, M=Middle, H=High School, I=Elem/Mid Combo, A=All Schools |\n",
    "| category_cd_modified | object | New Feature - simplified category_cd to distinguish between school types vs combined school levels |\n",
    "| crime_per_c_num | float64 | Number of crimes or acts of violence per 100 students at the school level (0-13) |\n",
    "| Majority_Minority | object | New Feature - classifying schools as having majority student body from minority racial groups (0 = Majority of non minority, 1 = Majority of minority |\n",
    "| MinorityFemalePct | float64 | Percentage of female minorities at the school level (0-100) |\n",
    "| MinorityMalePct | float64 | Percentage of male minorities at the school (0-100) |\n",
    "| MinorityOverallPct | float64 | New Feature - Minority Overall Percentage (0-100) |\n",
    "| school_type_txt | object | Description of school type (Regular School, Magnet School, etc.) |\n",
    "| short_susp_per_c_num | float64 | Short term suspensions per 100 students at the school level (0-181) |\n",
    "| student_num | float64 | School size or number of students at the school level (8-2966) |\n",
    "| tchyrs_0thru3_pct | float64 | Percentage of teachers with 0-3 years of teaching experience (0.0-1.0) |\n",
    "| Year | int64 | New Feature - School Year (2014-2017) |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "### Background\n",
    "\n",
    "For this analysis, our group start with the dataset from Lab1. The dataset contains North Carolina Public Schools Report Card and Statistical Profiles Data sets from the years 2014 to 2017. Currently there are 9371 records with 289 variables in this data. The preparation procedure to get to this dataset from original tables are located here:\n",
    "\n",
    "Script to process the dataset 2014 to 2019 seperately \n",
    "https://github.com/fredpoon/ds_7331_jyrf_eda/blob/master/Data_Prep/PublicSchools2014to2019_MLnew.ipynb\n",
    "\n",
    "Script to merge 2014 to 2017 datasets together\n",
    "https://github.com/fredpoon/ds_7331_jyrf_eda/blob/master/Data_Prep/PublicSchools2014to2019_MLnew_merge.ipynb\n",
    "\n",
    "In the starting dataset, all the categoricial variables are stored as \"object\". In order to be able to utilize it in our machine learning model, we conduct a one-hot encoding procedure to convert all of them into continuous variables. The procedure is shown below.\n",
    "\n",
    "The construction of code chunk is referred to Dr. Drew's github repository, [https://github.com/jakemdrew/EducationDataNC](https://github.com/jakemdrew/EducationDataNC/tree/master/Data%20Documentation)\n",
    "\n",
    "### One-Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vphone_ad</th>\n",
       "      <th>street_ad</th>\n",
       "      <th>scity_ad</th>\n",
       "      <th>szip_ad</th>\n",
       "      <th>category_cd</th>\n",
       "      <th>url_ad</th>\n",
       "      <th>grade_range_cd</th>\n",
       "      <th>calendar_type_txt</th>\n",
       "      <th>sna_pgm_type_cd</th>\n",
       "      <th>school_type_txt</th>\n",
       "      <th>...</th>\n",
       "      <th>MinorityFemalePct</th>\n",
       "      <th>MinorityMalePct</th>\n",
       "      <th>PacificIslandFemalePct</th>\n",
       "      <th>PacificIslandMalePct</th>\n",
       "      <th>PacificIslandPct</th>\n",
       "      <th>TwoOrMoreFemalePct</th>\n",
       "      <th>TwoOrMoreMalePct</th>\n",
       "      <th>TwoOrMorePct</th>\n",
       "      <th>unit_code</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(336)506-4001</td>\n",
       "      <td>1247 Jimmie Kerr Road</td>\n",
       "      <td>Graham</td>\n",
       "      <td>27253.0</td>\n",
       "      <td>H</td>\n",
       "      <td>http://amc.abss.k12.nc.us</td>\n",
       "      <td>9-12</td>\n",
       "      <td>Regular School, Traditional Calendar</td>\n",
       "      <td>R</td>\n",
       "      <td>Regular School</td>\n",
       "      <td>...</td>\n",
       "      <td>0.243243</td>\n",
       "      <td>0.067568</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.013514</td>\n",
       "      <td>0.013514</td>\n",
       "      <td>10303</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(336)578-1366</td>\n",
       "      <td>2518 NC 54</td>\n",
       "      <td>Graham</td>\n",
       "      <td>27253.0</td>\n",
       "      <td>E</td>\n",
       "      <td>http://awe.abss.k12.nc.us</td>\n",
       "      <td>PK-5</td>\n",
       "      <td>Regular School, Traditional Calendar</td>\n",
       "      <td>R</td>\n",
       "      <td>Regular School</td>\n",
       "      <td>...</td>\n",
       "      <td>0.157699</td>\n",
       "      <td>0.163265</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.014842</td>\n",
       "      <td>0.020408</td>\n",
       "      <td>0.035250</td>\n",
       "      <td>10304</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(336)538-6030</td>\n",
       "      <td>2832 N NC 87</td>\n",
       "      <td>Elon</td>\n",
       "      <td>27244.0</td>\n",
       "      <td>E</td>\n",
       "      <td>http://aoe.abss.k12.nc.us</td>\n",
       "      <td>K-5</td>\n",
       "      <td>Regular School, Traditional Calendar</td>\n",
       "      <td>R</td>\n",
       "      <td>Regular School</td>\n",
       "      <td>...</td>\n",
       "      <td>0.094096</td>\n",
       "      <td>0.107011</td>\n",
       "      <td>0.001845</td>\n",
       "      <td>0.001845</td>\n",
       "      <td>0.00369</td>\n",
       "      <td>0.011070</td>\n",
       "      <td>0.012915</td>\n",
       "      <td>0.023985</td>\n",
       "      <td>10308</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(336)570-6195</td>\n",
       "      <td>2229 Broadview Drive</td>\n",
       "      <td>Burlington</td>\n",
       "      <td>27217.0</td>\n",
       "      <td>M</td>\n",
       "      <td>http://brm.abss.k12.nc.us/</td>\n",
       "      <td>6-8</td>\n",
       "      <td>Regular School, Traditional Calendar</td>\n",
       "      <td>R</td>\n",
       "      <td>Regular School</td>\n",
       "      <td>...</td>\n",
       "      <td>0.445980</td>\n",
       "      <td>0.463568</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.011307</td>\n",
       "      <td>0.013819</td>\n",
       "      <td>0.025126</td>\n",
       "      <td>10310</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(336)538-8700</td>\n",
       "      <td>3720 Bonnar Bridge Parkway</td>\n",
       "      <td>Burlington</td>\n",
       "      <td>27215.0</td>\n",
       "      <td>E</td>\n",
       "      <td>http://hle.abss.k12.nc.us</td>\n",
       "      <td>K-5</td>\n",
       "      <td>Regular School, Traditional Calendar</td>\n",
       "      <td>R</td>\n",
       "      <td>Regular School</td>\n",
       "      <td>...</td>\n",
       "      <td>0.164134</td>\n",
       "      <td>0.173252</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.019757</td>\n",
       "      <td>0.028875</td>\n",
       "      <td>0.048632</td>\n",
       "      <td>10312</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 259 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       vphone_ad                   street_ad    scity_ad  szip_ad category_cd  \\\n",
       "0  (336)506-4001       1247 Jimmie Kerr Road      Graham  27253.0           H   \n",
       "1  (336)578-1366                  2518 NC 54      Graham  27253.0           E   \n",
       "2  (336)538-6030                2832 N NC 87        Elon  27244.0           E   \n",
       "3  (336)570-6195        2229 Broadview Drive  Burlington  27217.0           M   \n",
       "4  (336)538-8700  3720 Bonnar Bridge Parkway  Burlington  27215.0           E   \n",
       "\n",
       "                       url_ad grade_range_cd  \\\n",
       "0   http://amc.abss.k12.nc.us           9-12   \n",
       "1   http://awe.abss.k12.nc.us           PK-5   \n",
       "2   http://aoe.abss.k12.nc.us            K-5   \n",
       "3  http://brm.abss.k12.nc.us/            6-8   \n",
       "4   http://hle.abss.k12.nc.us            K-5   \n",
       "\n",
       "                      calendar_type_txt sna_pgm_type_cd school_type_txt  ...  \\\n",
       "0  Regular School, Traditional Calendar               R  Regular School  ...   \n",
       "1  Regular School, Traditional Calendar               R  Regular School  ...   \n",
       "2  Regular School, Traditional Calendar               R  Regular School  ...   \n",
       "3  Regular School, Traditional Calendar               R  Regular School  ...   \n",
       "4  Regular School, Traditional Calendar               R  Regular School  ...   \n",
       "\n",
       "  MinorityFemalePct MinorityMalePct PacificIslandFemalePct  \\\n",
       "0          0.243243        0.067568               0.000000   \n",
       "1          0.157699        0.163265               0.000000   \n",
       "2          0.094096        0.107011               0.001845   \n",
       "3          0.445980        0.463568               0.000000   \n",
       "4          0.164134        0.173252               0.000000   \n",
       "\n",
       "  PacificIslandMalePct  PacificIslandPct  TwoOrMoreFemalePct  \\\n",
       "0             0.000000           0.00000            0.000000   \n",
       "1             0.000000           0.00000            0.014842   \n",
       "2             0.001845           0.00369            0.011070   \n",
       "3             0.000000           0.00000            0.011307   \n",
       "4             0.000000           0.00000            0.019757   \n",
       "\n",
       "   TwoOrMoreMalePct TwoOrMorePct unit_code  Year  \n",
       "0          0.013514     0.013514     10303  2014  \n",
       "1          0.020408     0.035250     10304  2014  \n",
       "2          0.012915     0.023985     10308  2014  \n",
       "3          0.013819     0.025126     10310  2014  \n",
       "4          0.028875     0.048632     10312  2014  \n",
       "\n",
       "[5 rows x 259 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# For multiple line outputs\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "# read in the csv file\n",
    "schoolData = pd.read_csv('https://raw.githubusercontent.com/fredpoon/ds_7331_jyrf_eda/master/PublicSchools2014to2017_YZ.csv') \n",
    "\n",
    "schoolData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*********After: Removing columns with >= uniqueThreshold unique values***********\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9731 entries, 0 to 9730\n",
      "Columns: 250 entries, szip_ad to Year\n",
      "dtypes: float64(237), int64(2), object(11)\n",
      "memory usage: 18.6+ MB\n",
      "\n",
      "Columns Deleted:  9\n"
     ]
    }
   ],
   "source": [
    "#Locate the categorical variables in dataset\n",
    "sD_nominal = schoolData.loc[:, (schoolData.dtypes == object)]\n",
    "uniqueThreshold = 25\n",
    "\n",
    "#Delete categorical columns with > 25 unique values (Each unique value becomes a column during one-hot encoding)\n",
    "oneHotUniqueValueCounts = schoolData[sD_nominal.columns].apply(lambda x: x.nunique())\n",
    "oneHotUniqueValueCols = oneHotUniqueValueCounts[oneHotUniqueValueCounts >= uniqueThreshold].index\n",
    "schoolData.drop(oneHotUniqueValueCols, axis=1, inplace=True) \n",
    "\n",
    "#Review dataset contents one hot high unique value drops\n",
    "print('*********After: Removing columns with >= uniqueThreshold unique values***********')\n",
    "schoolData.info(verbose=False)\n",
    "print ('\\r\\nColumns Deleted: ', len(oneHotUniqueValueCols))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"SPG Grade\" is our response variable and \"SPG Score\" is the continous expression of it. We have to remove them from the original dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Keep an original copy of the Data\n",
    "schoolData_org = schoolData\n",
    "\n",
    "#Pop out the SPG information from the Data\n",
    "schoolData_SPG = schoolData.pop('SPG Grade')\n",
    "schoolData_SPGScore = schoolData.pop('SPG Score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9731 entries, 0 to 9730\n",
      "Data columns (total 248 columns):\n",
      "szip_ad                                float64\n",
      "category_cd                            object\n",
      "calendar_type_txt                      object\n",
      "sna_pgm_type_cd                        object\n",
      "school_type_txt                        object\n",
      "calendar_only_txt                      object\n",
      "title1_type_cd                         object\n",
      "esea_status                            object\n",
      "student_num                            float64\n",
      "lea_avg_student_num                    float64\n",
      "st_avg_student_num                     float64\n",
      "Grad_project_status                    object\n",
      "Math I_Size                            float64\n",
      "lea_total_expense_num                  float64\n",
      "lea_salary_expense_pct                 float64\n",
      "lea_services_expense_pct               float64\n",
      "lea_supplies_expense_pct               float64\n",
      "lea_instruct_equip_exp_pct             float64\n",
      "lea_federal_perpupil_num               float64\n",
      "lea_local_perpupil_num                 float64\n",
      "lea_state_perpupil_num                 float64\n",
      "EVAAS Growth Status                    object\n",
      "EVAAS Growth Score                     float64\n",
      "Science Score                          float64\n",
      "EOG/EOCSubjects_CACR_All               float64\n",
      "EOGGr3_CACR_All                        float64\n",
      "EOGGr4_CACR_All                        float64\n",
      "EOGGr5_CACR_All                        float64\n",
      "EOCMathI_CACR_AmericanIndian           float64\n",
      "EOCSubjects_CACR_AmericanIndian        float64\n",
      "EOG/EOCSubjects_CACR_AmericanIndian    float64\n",
      "EOGGr3_CACR_AmericanIndian             float64\n",
      "EOGGr4_CACR_AmericanIndian             float64\n",
      "EOGGr5_CACR_AmericanIndian             float64\n",
      "EOGMathGr3_CACR_AmericanIndian         float64\n",
      "EOGMathGr3-8_CACR_AmericanIndian       float64\n",
      "EOGMathGr4_CACR_AmericanIndian         float64\n",
      "EOGMathGr5_CACR_AmericanIndian         float64\n",
      "EOGReadingGr3-8_CACR_AmericanIndian    float64\n",
      "EOGScienceGr5_CACR_AmericanIndian      float64\n",
      "EOGScienceGr5&8_CACR_AmericanIndian    float64\n",
      "EOGSubjects_CACR_AmericanIndian        float64\n",
      "EOCMathI_CACR_Asian                    float64\n",
      "EOCSubjects_CACR_Asian                 float64\n",
      "EOG/EOCSubjects_CACR_Asian             float64\n",
      "EOGGr3_CACR_Asian                      float64\n",
      "EOGGr4_CACR_Asian                      float64\n",
      "EOGGr5_CACR_Asian                      float64\n",
      "EOGMathGr3_CACR_Asian                  float64\n",
      "EOGMathGr3-8_CACR_Asian                float64\n",
      "EOGMathGr4_CACR_Asian                  float64\n",
      "EOGMathGr5_CACR_Asian                  float64\n",
      "EOGScienceGr5&8_CACR_Asian             float64\n",
      "EOGSubjects_CACR_Asian                 float64\n",
      "EOCMathI_CACR_Black                    float64\n",
      "EOG/EOCSubjects_CACR_Black             float64\n",
      "EOGGr3_CACR_Black                      float64\n",
      "EOGGr4_CACR_Black                      float64\n",
      "EOGGr5_CACR_Black                      float64\n",
      "EOGMathGr3_CACR_Black                  float64\n",
      "EOGMathGr3-8_CACR_Black                float64\n",
      "EOGMathGr4_CACR_Black                  float64\n",
      "EOGMathGr5_CACR_Black                  float64\n",
      "EOGReadingGr3_CACR_Black               float64\n",
      "EOGReadingGr3-8_CACR_Black             float64\n",
      "EOGReadingGr4_CACR_Black               float64\n",
      "EOGReadingGr5_CACR_Black               float64\n",
      "EOGScienceGr5_CACR_Black               float64\n",
      "EOGScienceGr5&8_CACR_Black             float64\n",
      "EOGSubjects_CACR_Black                 float64\n",
      "EOCMathI_CACR_Hispanic                 float64\n",
      "EOG/EOCSubjects_CACR_Hispanic          float64\n",
      "EOGGr3_CACR_Hispanic                   float64\n",
      "EOGGr4_CACR_Hispanic                   float64\n",
      "EOGGr5_CACR_Hispanic                   float64\n",
      "EOGMathGr3_CACR_Hispanic               float64\n",
      "EOGMathGr3-8_CACR_Hispanic             float64\n",
      "EOGMathGr4_CACR_Hispanic               float64\n",
      "EOGMathGr5_CACR_Hispanic               float64\n",
      "EOGReadingGr3_CACR_Hispanic            float64\n",
      "EOGReadingGr3-8_CACR_Hispanic          float64\n",
      "EOGReadingGr4_CACR_Hispanic            float64\n",
      "EOGReadingGr5_CACR_Hispanic            float64\n",
      "EOGScienceGr5&8_CACR_Hispanic          float64\n",
      "EOGSubjects_CACR_Hispanic              float64\n",
      "EOCMathI_CACR_TwoorMoreRaces           float64\n",
      "EOCSubjects_CACR_TwoorMoreRaces        float64\n",
      "EOG/EOCSubjects_CACR_TwoorMoreRaces    float64\n",
      "EOGGr3_CACR_TwoorMoreRaces             float64\n",
      "EOGGr4_CACR_TwoorMoreRaces             float64\n",
      "EOGGr5_CACR_TwoorMoreRaces             float64\n",
      "EOGMathGr3_CACR_TwoorMoreRaces         float64\n",
      "EOGMathGr3-8_CACR_TwoorMoreRaces       float64\n",
      "EOGMathGr4_CACR_TwoorMoreRaces         float64\n",
      "EOGMathGr5_CACR_TwoorMoreRaces         float64\n",
      "EOGReadingGr3-8_CACR_TwoorMoreRaces    float64\n",
      "EOGScienceGr5&8_CACR_TwoorMoreRaces    float64\n",
      "EOGSubjects_CACR_TwoorMoreRaces        float64\n",
      "EOG/EOCSubjects_CACR_White             float64\n",
      "EOGGr4_CACR_White                      float64\n",
      "EOGMathGr3-8_CACR_White                float64\n",
      "EOGScienceGr5&8_CACR_White             float64\n",
      "EOCMathI_CACR_EDS                      float64\n",
      "EOG/EOCSubjects_CACR_EDS               float64\n",
      "EOGMathGr3-8_CACR_EDS                  float64\n",
      "EOGReadingGr3-8_CACR_EDS               float64\n",
      "EOGReadingGr5_CACR_EDS                 float64\n",
      "EOGScienceGr5&8_CACR_EDS               float64\n",
      "EOCMathI_CACR_LEP                      float64\n",
      "EOCMathI_GLP_LEP                       float64\n",
      "EOCSubjects_CACR_LEP                   float64\n",
      "EOCSubjects_GLP_LEP                    float64\n",
      "EOG/EOCSubjects_CACR_LEP               float64\n",
      "EOGGr3_CACR_LEP                        float64\n",
      "EOGGr4_CACR_LEP                        float64\n",
      "EOGGr5_CACR_LEP                        float64\n",
      "EOGMathGr3_CACR_LEP                    float64\n",
      "EOGMathGr3-8_CACR_LEP                  float64\n",
      "EOGMathGr4_CACR_LEP                    float64\n",
      "EOGMathGr5_CACR_LEP                    float64\n",
      "EOGReadingGr3_CACR_LEP                 float64\n",
      "EOGReadingGr3-8_CACR_LEP               float64\n",
      "EOGReadingGr3-8_GLP_LEP                float64\n",
      "EOGReadingGr4_CACR_LEP                 float64\n",
      "EOGReadingGr4_GLP_LEP                  float64\n",
      "EOGReadingGr5_CACR_LEP                 float64\n",
      "EOGReadingGr5_GLP_LEP                  float64\n",
      "EOGScienceGr5_CACR_LEP                 float64\n",
      "EOGScienceGr5&8_CACR_LEP               float64\n",
      "EOCMathI_CACR_SWD                      float64\n",
      "EOCMathI_GLP_SWD                       float64\n",
      "EOCSubjects_CACR_SWD                   float64\n",
      "EOG/EOCSubjects_CACR_SWD               float64\n",
      "EOGGr3_CACR_SWD                        float64\n",
      "EOGGr4_CACR_SWD                        float64\n",
      "EOGGr5_CACR_SWD                        float64\n",
      "EOGMathGr3_CACR_SWD                    float64\n",
      "EOGMathGr3_GLP_SWD                     float64\n",
      "EOGMathGr3-8_CACR_SWD                  float64\n",
      "EOGMathGr4_CACR_SWD                    float64\n",
      "EOGMathGr5_CACR_SWD                    float64\n",
      "EOGReadingGr3_CACR_SWD                 float64\n",
      "EOGReadingGr3-8_CACR_SWD               float64\n",
      "EOGReadingGr3-8_GLP_SWD                float64\n",
      "EOGReadingGr4_CACR_SWD                 float64\n",
      "EOGReadingGr4_GLP_SWD                  float64\n",
      "EOGReadingGr5_CACR_SWD                 float64\n",
      "EOGReadingGr5_GLP_SWD                  float64\n",
      "EOGScienceGr5_CACR_SWD                 float64\n",
      "EOGScienceGr5&8_CACR_SWD               float64\n",
      "EOGSubjects_CACR_SWD                   float64\n",
      "EOCMathI_CACR_AIG                      float64\n",
      "EOG/EOCSubjects_CACR_AIG               float64\n",
      "EOGGr3_CACR_AIG                        float64\n",
      "EOGGr4_CACR_AIG                        float64\n",
      "EOGGr5_CACR_AIG                        float64\n",
      "EOGMathGr3_CACR_AIG                    float64\n",
      "EOGMathGr3-8_CACR_AIG                  float64\n",
      "EOGMathGr4_CACR_AIG                    float64\n",
      "EOGMathGr5_CACR_AIG                    float64\n",
      "EOGScienceGr5&8_CACR_AIG               float64\n",
      "EOGSubjects_CACR_AIG                   float64\n",
      "pct_GCE_ALL                            float64\n",
      "MathGr3-8_pTarget_PctMet               float64\n",
      "SciGr5&8_pTarget_PctMet                float64\n",
      "TotalTargets_pTarget_PctMet            float64\n",
      "Category_Cd                            object\n",
      "lea_sat_avg_score_num                  float64\n",
      "lea_sat_participation_pct              float64\n",
      "lea_ap_participation_pct               float64\n",
      "lea_ap_pct_3_or_above                  float64\n",
      "lea_ib_pct_4_or_above                  float64\n",
      "avg_daily_attend_pct                   float64\n",
      "crime_per_c_num                        float64\n",
      "short_susp_per_c_num                   float64\n",
      "long_susp_per_c_num                    float64\n",
      "expelled_per_c_num                     float64\n",
      "stud_internet_comp_num                 float64\n",
      "lea_avg_daily_attend_pct               float64\n",
      "lea_crime_per_c_num                    float64\n",
      "lea_short_susp_per_c_num               float64\n",
      "lea_long_susp_per_c_num                float64\n",
      "lea_expelled_per_c_num                 float64\n",
      "lea_stud_internet_comp_num             float64\n",
      "st_crime_per_c_num                     float64\n",
      "flicensed_teach_pct                    float64\n",
      "tchyrs_0thru3_pct                      float64\n",
      "tchyrs_4thru10_pct                     float64\n",
      "tchyrs_11plus_pct                      float64\n",
      "nbpts_num                              float64\n",
      "advance_dgr_pct                        float64\n",
      "_1yr_tchr_trnovr_pct                   float64\n",
      "lateral_teach_pct                      float64\n",
      "lea_flicensed_teach_pct                float64\n",
      "lea_tchyrs_0thru3_pct                  float64\n",
      "lea_tchyrs_4thru10_pct                 float64\n",
      "lea_tchyrs_11plus_pct                  float64\n",
      "lea_nbpts_num                          float64\n",
      "lea_advance_dgr_pct                    float64\n",
      "lea_1yr_tchr_trnovr_pct                float64\n",
      "lea_emer_prov_teach_pct                float64\n",
      "st_flicensed_teach_pct                 float64\n",
      "st_tchyrs_0thru3_pct                   float64\n",
      "st_1yr_tchr_trnovr_pct                 float64\n",
      "st_emer_prov_teach_pct                 float64\n",
      "0-3 Years_LEA_Exp_Pct_Prin             float64\n",
      "10+ Years_LEA_Exp_Pct_Prin             float64\n",
      "4-10 Years_LEA_Exp_Pct_Prin            float64\n",
      "Accomplished_TCHR_Standard 1_Pct       float64\n",
      "Accomplished_TCHR_Standard 2_Pct       float64\n",
      "Accomplished_TCHR_Standard 3_Pct       float64\n",
      "Accomplished_TCHR_Standard 4_Pct       float64\n",
      "Accomplished_TCHR_Standard 5_Pct       float64\n",
      "Developing_TCHR_Standard 1_Pct         float64\n",
      "Developing_TCHR_Standard 2_Pct         float64\n",
      "Developing_TCHR_Standard 3_Pct         float64\n",
      "Developing_TCHR_Standard 4_Pct         float64\n",
      "Developing_TCHR_Standard 5_Pct         float64\n",
      "Distinguished_TCHR_Standard 1_Pct      float64\n",
      "Distinguished_TCHR_Standard 2_Pct      float64\n",
      "Distinguished_TCHR_Standard 3_Pct      float64\n",
      "Distinguished_TCHR_Standard 4_Pct      float64\n",
      "Distinguished_TCHR_Standard 5_Pct      float64\n",
      "Not Demostrated_TCHR_Standard 1_Pct    float64\n",
      "Not Demostrated_TCHR_Standard 2_Pct    float64\n",
      "Not Demostrated_TCHR_Standard 4_Pct    float64\n",
      "Proficient_TCHR_Standard 1_Pct         float64\n",
      "Proficient_TCHR_Standard 2_Pct         float64\n",
      "Proficient_TCHR_Standard 3_Pct         float64\n",
      "Proficient_TCHR_Standard 4_Pct         float64\n",
      "Proficient_TCHR_Standard 5_Pct         float64\n",
      "AsianFemalePct                         float64\n",
      "AsianMalePct                           float64\n",
      "BlackFemalePct                         float64\n",
      "BlackMalePct                           float64\n",
      "HispanicFemalePct                      float64\n",
      "HispanicMalePct                        float64\n",
      "IndianFemalePct                        float64\n",
      "MinorityFemalePct                      float64\n",
      "MinorityMalePct                        float64\n",
      "PacificIslandFemalePct                 float64\n",
      "PacificIslandMalePct                   float64\n",
      "PacificIslandPct                       float64\n",
      "TwoOrMoreFemalePct                     float64\n",
      "TwoOrMoreMalePct                       float64\n",
      "TwoOrMorePct                           float64\n",
      "unit_code                              int64\n",
      "Year                                   int64\n",
      "dtypes: float64(236), int64(2), object(10)\n",
      "memory usage: 18.4+ MB\n"
     ]
    }
   ],
   "source": [
    "schoolData.info(verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also need to get rid of all the columns that directly used to calculate SPG Grade and Score. \n",
    "(Expand it)\n",
    "For example: EOG_XXX, EOC_XXX.\n",
    "\n",
    "After removing them, we display the information of the variables to make sure we don't have them in the dataset anymore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9731 entries, 0 to 9730\n",
      "Data columns (total 108 columns):\n",
      "szip_ad                                float64\n",
      "category_cd                            object\n",
      "calendar_type_txt                      object\n",
      "sna_pgm_type_cd                        object\n",
      "school_type_txt                        object\n",
      "calendar_only_txt                      object\n",
      "title1_type_cd                         object\n",
      "esea_status                            object\n",
      "student_num                            float64\n",
      "lea_avg_student_num                    float64\n",
      "st_avg_student_num                     float64\n",
      "Grad_project_status                    object\n",
      "Math I_Size                            float64\n",
      "lea_total_expense_num                  float64\n",
      "lea_salary_expense_pct                 float64\n",
      "lea_services_expense_pct               float64\n",
      "lea_supplies_expense_pct               float64\n",
      "lea_instruct_equip_exp_pct             float64\n",
      "lea_federal_perpupil_num               float64\n",
      "lea_local_perpupil_num                 float64\n",
      "lea_state_perpupil_num                 float64\n",
      "EVAAS Growth Status                    object\n",
      "pct_GCE_ALL                            float64\n",
      "MathGr3-8_pTarget_PctMet               float64\n",
      "SciGr5&8_pTarget_PctMet                float64\n",
      "TotalTargets_pTarget_PctMet            float64\n",
      "Category_Cd                            object\n",
      "lea_sat_avg_score_num                  float64\n",
      "lea_sat_participation_pct              float64\n",
      "lea_ap_participation_pct               float64\n",
      "lea_ap_pct_3_or_above                  float64\n",
      "lea_ib_pct_4_or_above                  float64\n",
      "avg_daily_attend_pct                   float64\n",
      "crime_per_c_num                        float64\n",
      "short_susp_per_c_num                   float64\n",
      "long_susp_per_c_num                    float64\n",
      "expelled_per_c_num                     float64\n",
      "stud_internet_comp_num                 float64\n",
      "lea_avg_daily_attend_pct               float64\n",
      "lea_crime_per_c_num                    float64\n",
      "lea_short_susp_per_c_num               float64\n",
      "lea_long_susp_per_c_num                float64\n",
      "lea_expelled_per_c_num                 float64\n",
      "lea_stud_internet_comp_num             float64\n",
      "st_crime_per_c_num                     float64\n",
      "flicensed_teach_pct                    float64\n",
      "tchyrs_0thru3_pct                      float64\n",
      "tchyrs_4thru10_pct                     float64\n",
      "tchyrs_11plus_pct                      float64\n",
      "nbpts_num                              float64\n",
      "advance_dgr_pct                        float64\n",
      "_1yr_tchr_trnovr_pct                   float64\n",
      "lateral_teach_pct                      float64\n",
      "lea_flicensed_teach_pct                float64\n",
      "lea_tchyrs_0thru3_pct                  float64\n",
      "lea_tchyrs_4thru10_pct                 float64\n",
      "lea_tchyrs_11plus_pct                  float64\n",
      "lea_nbpts_num                          float64\n",
      "lea_advance_dgr_pct                    float64\n",
      "lea_1yr_tchr_trnovr_pct                float64\n",
      "lea_emer_prov_teach_pct                float64\n",
      "st_flicensed_teach_pct                 float64\n",
      "st_tchyrs_0thru3_pct                   float64\n",
      "st_1yr_tchr_trnovr_pct                 float64\n",
      "st_emer_prov_teach_pct                 float64\n",
      "0-3 Years_LEA_Exp_Pct_Prin             float64\n",
      "10+ Years_LEA_Exp_Pct_Prin             float64\n",
      "4-10 Years_LEA_Exp_Pct_Prin            float64\n",
      "Accomplished_TCHR_Standard 1_Pct       float64\n",
      "Accomplished_TCHR_Standard 2_Pct       float64\n",
      "Accomplished_TCHR_Standard 3_Pct       float64\n",
      "Accomplished_TCHR_Standard 4_Pct       float64\n",
      "Accomplished_TCHR_Standard 5_Pct       float64\n",
      "Developing_TCHR_Standard 1_Pct         float64\n",
      "Developing_TCHR_Standard 2_Pct         float64\n",
      "Developing_TCHR_Standard 3_Pct         float64\n",
      "Developing_TCHR_Standard 4_Pct         float64\n",
      "Developing_TCHR_Standard 5_Pct         float64\n",
      "Distinguished_TCHR_Standard 1_Pct      float64\n",
      "Distinguished_TCHR_Standard 2_Pct      float64\n",
      "Distinguished_TCHR_Standard 3_Pct      float64\n",
      "Distinguished_TCHR_Standard 4_Pct      float64\n",
      "Distinguished_TCHR_Standard 5_Pct      float64\n",
      "Not Demostrated_TCHR_Standard 1_Pct    float64\n",
      "Not Demostrated_TCHR_Standard 2_Pct    float64\n",
      "Not Demostrated_TCHR_Standard 4_Pct    float64\n",
      "Proficient_TCHR_Standard 1_Pct         float64\n",
      "Proficient_TCHR_Standard 2_Pct         float64\n",
      "Proficient_TCHR_Standard 3_Pct         float64\n",
      "Proficient_TCHR_Standard 4_Pct         float64\n",
      "Proficient_TCHR_Standard 5_Pct         float64\n",
      "AsianFemalePct                         float64\n",
      "AsianMalePct                           float64\n",
      "BlackFemalePct                         float64\n",
      "BlackMalePct                           float64\n",
      "HispanicFemalePct                      float64\n",
      "HispanicMalePct                        float64\n",
      "IndianFemalePct                        float64\n",
      "MinorityFemalePct                      float64\n",
      "MinorityMalePct                        float64\n",
      "PacificIslandFemalePct                 float64\n",
      "PacificIslandMalePct                   float64\n",
      "PacificIslandPct                       float64\n",
      "TwoOrMoreFemalePct                     float64\n",
      "TwoOrMoreMalePct                       float64\n",
      "TwoOrMorePct                           float64\n",
      "unit_code                              int64\n",
      "Year                                   int64\n",
      "dtypes: float64(96), int64(2), object(10)\n",
      "memory usage: 8.0+ MB\n"
     ]
    }
   ],
   "source": [
    "# Remove All the Columns that directly used to calculate SPG Grade and Score\n",
    "schoolData.drop(schoolData.iloc[:, 22:162], inplace=True, axis=1)\n",
    "schoolData.info(verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below procedure do the one-hot encoding for the left categorical variable. As shown below we have a total of 20 categorical variables to encode and we end up with 40 variables after the encoding process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Isolate remaining categorical variables\n",
    "begColumnCt = len(schoolData.columns)\n",
    "\n",
    "#one hot encode categorical variables\n",
    "schoolData = pd.get_dummies(data=schoolData,drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns To One-Hot Encode:  20\n",
      "\n",
      "*********After: Adding New Columns Via One-Hot Encoding*************************\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9731 entries, 0 to 9730\n",
      "Columns: 148 entries, szip_ad to Category_Cd_T\n",
      "dtypes: float64(96), int64(2), uint8(50)\n",
      "memory usage: 7.7 MB\n",
      "\n",
      "New Columns Created Via One-Hot Encoding:  40\n"
     ]
    }
   ],
   "source": [
    "#Determine change in column count\n",
    "endColumnCt = len(schoolData.columns)\n",
    "columnsAdded = endColumnCt - begColumnCt\n",
    "\n",
    "\n",
    "#Review dataset contents one hot high unique value drops\n",
    "print('Columns To One-Hot Encode: ', len(sD_nominal.columns))\n",
    "print('\\r\\n*********After: Adding New Columns Via One-Hot Encoding*************************')\n",
    "schoolData.info(verbose=False)\n",
    "print ('\\r\\nNew Columns Created Via One-Hot Encoding: ', columnsAdded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A dimension check of the dataset after the one-hot encoding process shows that we have a total of 9371 records with 148 seperate variables. All of the variables are in numerical format now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9731, 148)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>szip_ad</th>\n",
       "      <th>student_num</th>\n",
       "      <th>lea_avg_student_num</th>\n",
       "      <th>st_avg_student_num</th>\n",
       "      <th>Math I_Size</th>\n",
       "      <th>lea_total_expense_num</th>\n",
       "      <th>lea_salary_expense_pct</th>\n",
       "      <th>lea_services_expense_pct</th>\n",
       "      <th>lea_supplies_expense_pct</th>\n",
       "      <th>lea_instruct_equip_exp_pct</th>\n",
       "      <th>...</th>\n",
       "      <th>Grad_project_status_Y</th>\n",
       "      <th>EVAAS Growth Status_Exceeded</th>\n",
       "      <th>EVAAS Growth Status_Met</th>\n",
       "      <th>EVAAS Growth Status_NotMet</th>\n",
       "      <th>Category_Cd_A</th>\n",
       "      <th>Category_Cd_E</th>\n",
       "      <th>Category_Cd_H</th>\n",
       "      <th>Category_Cd_I</th>\n",
       "      <th>Category_Cd_M</th>\n",
       "      <th>Category_Cd_T</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>27253.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>954.0</td>\n",
       "      <td>837.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8028.59</td>\n",
       "      <td>0.613</td>\n",
       "      <td>0.078</td>\n",
       "      <td>0.086</td>\n",
       "      <td>0.011</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>27253.0</td>\n",
       "      <td>539.0</td>\n",
       "      <td>518.0</td>\n",
       "      <td>496.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8028.59</td>\n",
       "      <td>0.613</td>\n",
       "      <td>0.078</td>\n",
       "      <td>0.086</td>\n",
       "      <td>0.011</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>27244.0</td>\n",
       "      <td>547.0</td>\n",
       "      <td>518.0</td>\n",
       "      <td>496.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8028.59</td>\n",
       "      <td>0.613</td>\n",
       "      <td>0.078</td>\n",
       "      <td>0.086</td>\n",
       "      <td>0.011</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27217.0</td>\n",
       "      <td>800.0</td>\n",
       "      <td>768.0</td>\n",
       "      <td>665.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>8028.59</td>\n",
       "      <td>0.613</td>\n",
       "      <td>0.078</td>\n",
       "      <td>0.086</td>\n",
       "      <td>0.011</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>27215.0</td>\n",
       "      <td>664.0</td>\n",
       "      <td>518.0</td>\n",
       "      <td>496.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8028.59</td>\n",
       "      <td>0.613</td>\n",
       "      <td>0.078</td>\n",
       "      <td>0.086</td>\n",
       "      <td>0.011</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 148 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   szip_ad  student_num  lea_avg_student_num  st_avg_student_num  Math I_Size  \\\n",
       "0  27253.0         78.0                954.0               837.0          0.0   \n",
       "1  27253.0        539.0                518.0               496.0          0.0   \n",
       "2  27244.0        547.0                518.0               496.0          0.0   \n",
       "3  27217.0        800.0                768.0               665.0         26.0   \n",
       "4  27215.0        664.0                518.0               496.0          0.0   \n",
       "\n",
       "   lea_total_expense_num  lea_salary_expense_pct  lea_services_expense_pct  \\\n",
       "0                8028.59                   0.613                     0.078   \n",
       "1                8028.59                   0.613                     0.078   \n",
       "2                8028.59                   0.613                     0.078   \n",
       "3                8028.59                   0.613                     0.078   \n",
       "4                8028.59                   0.613                     0.078   \n",
       "\n",
       "   lea_supplies_expense_pct  lea_instruct_equip_exp_pct  ...  \\\n",
       "0                     0.086                       0.011  ...   \n",
       "1                     0.086                       0.011  ...   \n",
       "2                     0.086                       0.011  ...   \n",
       "3                     0.086                       0.011  ...   \n",
       "4                     0.086                       0.011  ...   \n",
       "\n",
       "   Grad_project_status_Y  EVAAS Growth Status_Exceeded  \\\n",
       "0                      0                             0   \n",
       "1                      0                             1   \n",
       "2                      0                             0   \n",
       "3                      0                             0   \n",
       "4                      0                             1   \n",
       "\n",
       "   EVAAS Growth Status_Met  EVAAS Growth Status_NotMet  Category_Cd_A  \\\n",
       "0                        0                           0              0   \n",
       "1                        0                           0              0   \n",
       "2                        1                           0              0   \n",
       "3                        0                           1              0   \n",
       "4                        0                           0              0   \n",
       "\n",
       "   Category_Cd_E  Category_Cd_H  Category_Cd_I  Category_Cd_M  Category_Cd_T  \n",
       "0              0              1              0              0              0  \n",
       "1              1              0              0              0              0  \n",
       "2              1              0              0              0              0  \n",
       "3              0              0              0              1              0  \n",
       "4              1              0              0              0              0  \n",
       "\n",
       "[5 rows x 148 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dimension of Dataset\n",
    "schoolData.shape\n",
    "\n",
    "schoolData.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We original have 148 features in the data table. We don't want to include this many features for model feasibility. However, as we have a data size requirement, and we also want the constructing model to be high quality. We decide to conduct a feature selection process to choose the most important features to use.\n",
    "\n",
    "There are many ways to conduct feature selection. In this project we use random forest and plot out feature importances of all features. The work below is not for feasible model construction (we didn't split train/test) but just for picking out the most important variables to use.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Random Forest apply to X with all variables\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clfa=RandomForestClassifier(n_estimators=100)\n",
    "clfa.fit(schoolData,schoolData_SPG)\n",
    "y_pred=clfa.predict(schoolData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy = 1.0 does not surprise us because we didn't to train/test splitting. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "print(\"Accuracy:\",metrics.accuracy_score(schoolData_SPG, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below plot reflect what features are important and their according weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "    table.eli5-weights tr:hover {\n",
       "        filter: brightness(85%);\n",
       "    }\n",
       "</style>\n",
       "\n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "        <table class=\"eli5-weights eli5-feature-importances\" style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto;\">\n",
       "    <thead>\n",
       "    <tr style=\"border: none;\">\n",
       "        <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">Weight</th>\n",
       "        <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
       "    </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 80.00%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0327\n",
       "                \n",
       "                    &plusmn; 0.0029\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                TotalTargets_pTarget_PctMet\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 92.55%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0080\n",
       "                \n",
       "                    &plusmn; 0.0005\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                EVAAS Growth Status_NotMet\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 94.97%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0045\n",
       "                \n",
       "                    &plusmn; 0.0012\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                MinorityMalePct\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 95.30%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0041\n",
       "                \n",
       "                    &plusmn; 0.0006\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                MinorityFemalePct\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 96.66%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0025\n",
       "                \n",
       "                    &plusmn; 0.0007\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                title1_type_cd_Y\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 97.13%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0020\n",
       "                \n",
       "                    &plusmn; 0.0002\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                AsianFemalePct\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 98.01%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0012\n",
       "                \n",
       "                    &plusmn; 0.0003\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                EVAAS Growth Status_Exceeded\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 98.40%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0009\n",
       "                \n",
       "                    &plusmn; 0.0002\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                BlackFemalePct\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 98.56%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0008\n",
       "                \n",
       "                    &plusmn; 0.0004\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                BlackMalePct\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 98.73%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0006\n",
       "                \n",
       "                    &plusmn; 0.0002\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                short_susp_per_c_num\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 98.91%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0005\n",
       "                \n",
       "                    &plusmn; 0.0005\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                avg_daily_attend_pct\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 99.31%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0003\n",
       "                \n",
       "                    &plusmn; 0.0002\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                HispanicMalePct\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 99.35%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0002\n",
       "                \n",
       "                    &plusmn; 0.0001\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                SciGr5&amp;8_pTarget_PctMet\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 99.38%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0002\n",
       "                \n",
       "                    &plusmn; 0.0004\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                MathGr3-8_pTarget_PctMet\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 99.55%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0001\n",
       "                \n",
       "                    &plusmn; 0.0001\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                nbpts_num\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 99.60%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0001\n",
       "                \n",
       "                    &plusmn; 0.0001\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                student_num\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 99.65%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0001\n",
       "                \n",
       "                    &plusmn; 0.0001\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                HispanicFemalePct\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 99.70%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0001\n",
       "                \n",
       "                    &plusmn; 0.0002\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                lea_sat_avg_score_num\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 99.81%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0000\n",
       "                \n",
       "                    &plusmn; 0.0001\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                lea_ap_participation_pct\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 99.89%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0000\n",
       "                \n",
       "                    &plusmn; 0.0001\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                lea_local_perpupil_num\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 99.89%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0000\n",
       "                \n",
       "                    &plusmn; 0.0001\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                unit_code\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 99.89%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0000\n",
       "                \n",
       "                    &plusmn; 0.0001\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                lea_tchyrs_11plus_pct\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 99.89%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0000\n",
       "                \n",
       "                    &plusmn; 0.0001\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                Accomplished_TCHR_Standard 4_Pct\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 99.89%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0000\n",
       "                \n",
       "                    &plusmn; 0.0001\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                lea_state_perpupil_num\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(0, 100.00%, 100.00%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0\n",
       "                \n",
       "                    &plusmn; 0.0000\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                Accomplished_TCHR_Standard 1_Pct\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(0, 100.00%, 100.00%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0\n",
       "                \n",
       "                    &plusmn; 0.0000\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                Accomplished_TCHR_Standard 2_Pct\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(0, 100.00%, 100.00%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0\n",
       "                \n",
       "                    &plusmn; 0.0000\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                Accomplished_TCHR_Standard 3_Pct\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(0, 100.00%, 100.00%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0\n",
       "                \n",
       "                    &plusmn; 0.0000\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                Accomplished_TCHR_Standard 5_Pct\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(0, 100.00%, 100.00%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0\n",
       "                \n",
       "                    &plusmn; 0.0000\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                Developing_TCHR_Standard 1_Pct\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(0, 100.00%, 100.00%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0\n",
       "                \n",
       "                    &plusmn; 0.0000\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                Developing_TCHR_Standard 2_Pct\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(0, 100.00%, 100.00%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0\n",
       "                \n",
       "                    &plusmn; 0.0000\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                4-10 Years_LEA_Exp_Pct_Prin\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(0, 100.00%, 100.00%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0\n",
       "                \n",
       "                    &plusmn; 0.0000\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                lea_federal_perpupil_num\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(0, 100.00%, 100.00%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0\n",
       "                \n",
       "                    &plusmn; 0.0000\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                Developing_TCHR_Standard 3_Pct\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(0, 100.00%, 100.00%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0\n",
       "                \n",
       "                    &plusmn; 0.0000\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                lea_instruct_equip_exp_pct\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(0, 100.00%, 100.00%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0\n",
       "                \n",
       "                    &plusmn; 0.0000\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                _1yr_tchr_trnovr_pct\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(0, 100.00%, 100.00%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0\n",
       "                \n",
       "                    &plusmn; 0.0000\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                Developing_TCHR_Standard 5_Pct\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(0, 100.00%, 100.00%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0\n",
       "                \n",
       "                    &plusmn; 0.0000\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                lea_flicensed_teach_pct\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(0, 100.00%, 100.00%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0\n",
       "                \n",
       "                    &plusmn; 0.0000\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                lea_tchyrs_0thru3_pct\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(0, 100.00%, 100.00%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0\n",
       "                \n",
       "                    &plusmn; 0.0000\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                lea_tchyrs_4thru10_pct\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(0, 100.00%, 100.00%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0\n",
       "                \n",
       "                    &plusmn; 0.0000\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                lea_nbpts_num\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(0, 100.00%, 100.00%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0\n",
       "                \n",
       "                    &plusmn; 0.0000\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                lea_advance_dgr_pct\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(0, 100.00%, 100.00%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0\n",
       "                \n",
       "                    &plusmn; 0.0000\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                lea_1yr_tchr_trnovr_pct\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(0, 100.00%, 100.00%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0\n",
       "                \n",
       "                    &plusmn; 0.0000\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                lea_emer_prov_teach_pct\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(0, 100.00%, 100.00%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0\n",
       "                \n",
       "                    &plusmn; 0.0000\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                st_flicensed_teach_pct\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(0, 100.00%, 100.00%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0\n",
       "                \n",
       "                    &plusmn; 0.0000\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                st_tchyrs_0thru3_pct\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(0, 100.00%, 100.00%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0\n",
       "                \n",
       "                    &plusmn; 0.0000\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                st_1yr_tchr_trnovr_pct\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(0, 100.00%, 100.00%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0\n",
       "                \n",
       "                    &plusmn; 0.0000\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                st_emer_prov_teach_pct\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(0, 100.00%, 100.00%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0\n",
       "                \n",
       "                    &plusmn; 0.0000\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                0-3 Years_LEA_Exp_Pct_Prin\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(0, 100.00%, 100.00%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0\n",
       "                \n",
       "                    &plusmn; 0.0000\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                10+ Years_LEA_Exp_Pct_Prin\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(0, 100.00%, 100.00%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0\n",
       "                \n",
       "                    &plusmn; 0.0000\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                Category_Cd_T\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "    \n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 100.00%); border: none;\">\n",
       "                <td colspan=\"2\" style=\"padding: 0 0.5em 0 0.5em; text-align: center; border: none; white-space: nowrap;\">\n",
       "                    <i>&hellip; 98 more &hellip;</i>\n",
       "                </td>\n",
       "            </tr>\n",
       "        \n",
       "    \n",
       "    </tbody>\n",
       "</table>\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#For feature importance\n",
    "import eli5\n",
    "from eli5.sklearn import PermutationImportance\n",
    "perm = PermutationImportance(clfa, random_state=1).fit(schoolData,schoolData_SPG)\n",
    "eli5.show_weights(perm, feature_names = schoolData.columns.tolist(), top=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To meet the data size requirement, we need to have as least 450,000/9371 = 48 variables to use for the data. \n",
    "\n",
    "To satisfy this we pick the first 50 variables to use. Notice that in the below variable list there are both continuous variables and the categorical variables after one-hot encoding. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9731, 50)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Pick and Choose variables\n",
    "schoolData_pick = schoolData[[\n",
    "'TotalTargets_pTarget_PctMet',\n",
    "'EVAAS Growth Status_NotMet',\n",
    "'MinorityMalePct',\n",
    "'MinorityFemalePct',\n",
    "'title1_type_cd_Y',\n",
    "'avg_daily_attend_pct',\n",
    "'short_susp_per_c_num',\n",
    "'BlackMalePct',\n",
    "'AsianFemalePct',\n",
    "'student_num',\n",
    "'HispanicMalePct',\n",
    "'SciGr5&8_pTarget_PctMet',\n",
    "'tchyrs_0thru3_pct',\n",
    "'tchyrs_11plus_pct',\n",
    "'Accomplished_TCHR_Standard 2_Pct',\n",
    "'Accomplished_TCHR_Standard 1_Pct',\n",
    "'Developing_TCHR_Standard 1_Pct',\n",
    "'Developing_TCHR_Standard 2_Pct',\n",
    "'Developing_TCHR_Standard 3_Pct',\n",
    "'Accomplished_TCHR_Standard 4_Pct',\n",
    "'4-10 Years_LEA_Exp_Pct_Prin',\n",
    "'Developing_TCHR_Standard 4_Pct',\n",
    "'Developing_TCHR_Standard 5_Pct',\n",
    "'10+ Years_LEA_Exp_Pct_Prin',\n",
    "'Accomplished_TCHR_Standard 3_Pct',\n",
    "'Accomplished_TCHR_Standard 5_Pct',\n",
    "'lea_state_perpupil_num',\n",
    "'st_emer_prov_teach_pct',\n",
    "'pct_GCE_ALL',\n",
    "'MathGr3-8_pTarget_PctMet',\n",
    "'lea_sat_avg_score_num',\n",
    "'lea_federal_perpupil_num',\n",
    "'lea_local_perpupil_num',\n",
    "'nbpts_num',\n",
    "'Distinguished_TCHR_Standard 2_Pct',\n",
    "'_1yr_tchr_trnovr_pct',\n",
    "'lateral_teach_pct',\n",
    "'0-3 Years_LEA_Exp_Pct_Prin',\n",
    "'lea_flicensed_teach_pct',\n",
    "'lea_tchyrs_4thru10_pct',\n",
    "'lea_tchyrs_11plus_pct',\n",
    "'lea_nbpts_num',\n",
    "'lea_advance_dgr_pct',\n",
    "'lea_1yr_tchr_trnovr_pct',\n",
    "'lea_emer_prov_teach_pct',\n",
    "'st_flicensed_teach_pct',\n",
    "'st_tchyrs_0thru3_pct',\n",
    "'st_1yr_tchr_trnovr_pct',\n",
    "'lea_tchyrs_0thru3_pct',\n",
    "'Category_Cd_T',\n",
    "]]\n",
    "\n",
    "# Dataset Dimension with picked variables\n",
    "schoolData_pick.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training/Testing Splitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To prepare our official SVM and Logistic regression modeling procedure, we need to split the dataset into training and testing set. We use the ShuffleSplit criteria below. We use a proportion of 80/20 for the training/testing dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ShuffleSplit(n_splits=3, random_state=None, test_size=0.2, train_size=None)\n"
     ]
    }
   ],
   "source": [
    "# Using ShuffleSplit for Training/Testing Split \n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "num_cv_iterations = 3\n",
    "num_instances = len(schoolData_SPG)\n",
    "cv_object = ShuffleSplit(n_splits=num_cv_iterations,\n",
    "                         test_size  = 0.2)\n",
    "                         \n",
    "print(cv_object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split X and Y into Training and Testing dataset\n",
    "for train_indices, test_indices in cv_object.split(schoolData_pick,schoolData_SPG): \n",
    "\n",
    "    Xsel_train = schoolData_pick.values[train_indices]\n",
    "    ysel_train = schoolData_SPG.values[train_indices]\n",
    "    Xall_train = schoolData.values[train_indices]\n",
    "    \n",
    "    Xsel_test = schoolData_pick.values[test_indices]\n",
    "    ysel_test = schoolData_SPG.values[test_indices]\n",
    "    Xall_test = schoolData.values[test_indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " With our feature selection (51 variables), check and make sure it contains most information. The way we conduct the validation is by running another random forest and check the accuracy. This accuracy of the current model (acc=0.733) is close to the model utilizing all the variables (acc=0.736). So we varify that our selection is reasonable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model with Selective Variables Accuracy: 0.7334360554699538\n",
      "Model with All Variables Accuracy: 0.7370313302516692\n"
     ]
    }
   ],
   "source": [
    "# Random Forest fitting with selective variables\n",
    "clf_rf=RandomForestClassifier(n_estimators=100)\n",
    "clf_rf.fit(Xsel_train,ysel_train)\n",
    "y_pred_rf=clf_rf.predict(Xsel_test)\n",
    "\n",
    "# Random Forest fitting with all variables\n",
    "clf_rf_all=RandomForestClassifier(n_estimators=100)\n",
    "clf_rf_all.fit(Xall_train,ysel_train)\n",
    "y_pred_rf_all=clf_rf_all.predict(Xall_test)\n",
    "\n",
    "print(\"Model with Selective Variables Accuracy:\",metrics.accuracy_score(ysel_test, y_pred_rf))\n",
    "print(\"Model with All Variables Accuracy:\",metrics.accuracy_score(ysel_test, y_pred_rf_all))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solving Data Imbalance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We find that our response variable (SPG_Grade) has a data balancing problem: The grade C is dominate the dataset with the largest propertion, followed by B or D. A and F are just a small propertion of the whole dataset. \n",
    "\n",
    "First we investigate the current class of the SPG Grade and found that the class \"A\" and \"A+NG\" are identical so we merge the two, the class \"I\" has incomplete information so we are removing it from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>9216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>3973</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           0\n",
       "count   9216\n",
       "unique     5\n",
       "top        C\n",
       "freq    3973"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "schoolData_SPG_org = schoolData_SPG\n",
    "schoolData_SPG = schoolData_SPG_org\n",
    "\n",
    "import numpy as np\n",
    "schoolData_SPG= np.select(\n",
    "    [\n",
    "        schoolData_SPG == 'A', \n",
    "        schoolData_SPG == 'B',\n",
    "        schoolData_SPG == 'C',\n",
    "        schoolData_SPG == 'D',\n",
    "        schoolData_SPG == 'F',\n",
    "        schoolData_SPG == 'A+NG',\n",
    "        schoolData_SPG == 'I'\n",
    "    ], \n",
    "    [\n",
    "        'A', \n",
    "        'B',\n",
    "        'C',\n",
    "        'D',\n",
    "        'F',\n",
    "        'A',\n",
    "        'NA'\n",
    "    ],\n",
    "    default='NA'\n",
    ")\n",
    "\n",
    "#Filter out the sample with \"NA\" on SPG Grade\n",
    "schoolData_SPG_new = schoolData_SPG[schoolData_SPG!='NA']\n",
    "schoolData_pick_new = schoolData_pick[schoolData_SPG!='NA']\n",
    "\n",
    "# Check if the levels of SPG Grade has been altered\n",
    "s = pd.DataFrame(schoolData_SPG_new)\n",
    "s.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After merging the class, we can see below a distribution of current SPG Grade. The grade C is dominate the dataset with the largest propertion, followed by B or D. A and F are just a small propertion of the whole dataset. We need to re-balance the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.FacetGrid at 0x132836c10>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Factor Plot for SPG Grade\n",
    "s.columns=['SPG Grade']\n",
    "                        \n",
    "sns.factorplot(\"SPG Grade\", data=s, aspect=2,\n",
    "                       kind=\"count\", order=['A','B','C','D','F'])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To solve this problem, we are using the crieteria below.\n",
    "\n",
    "#### Test 3 types of sampler: UnderSample all cases, UnderSample majority class, SMOTE Oversample\n",
    "\n",
    "Below we conduct 3 seperate procedures to produce 3 seperate sets of X and y from the original dataset. Those sets will be evaluate against each other and we will decide the best data balancing strategy to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9216, 50)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(9216,)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the dimension for X and y\n",
    "schoolData_pick_new.shape\n",
    "schoolData_SPG_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "# Undersample the dataset using the RandomUnderSampler \n",
    "# Set all class sizes equal to the smallest class.\n",
    "us = RandomUnderSampler()\n",
    "X_us, y_us = us.fit_sample(schoolData_pick_new, pd.DataFrame(schoolData_SPG_new))\n",
    "\n",
    "# Plot the new class distributions for y using the same funnction as above. \n",
    "#plot_class_dist(y_us)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "# Undersample the dataset using the RandomUnderSampler \n",
    "# Undersample the majority class only\n",
    "us = RandomUnderSampler(sampling_strategy='majority')\n",
    "X_us_maj, y_us_maj = us.fit_sample(schoolData_pick_new, pd.DataFrame(schoolData_SPG_new))\n",
    "\n",
    "# Plot the new class distributions for y using the same funnction as above. \n",
    "#plot_class_dist(y_us_maj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Oversample using SMOTE\n",
    "# Make all classes the same size as the majority class.\n",
    "# WARNING - This can exponentially increase the size of the input dataset.\n",
    "sm = SMOTE(sampling_strategy='not majority')\n",
    "X_sm, y_sm = sm.fit_sample(schoolData_pick_new, pd.DataFrame(schoolData_SPG_new))\n",
    "\n",
    "# Plot the new class distributions for y using the same funnction as above. \n",
    "#plot_class_dist(y_sm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By comparing the results for the 3 different methods dealing with data imbalance, we run random forest with the datasets we generated. Accuracy are measured with the results of the variables. As shown the SMOTE strategy get the highest accuracy. It will be used for the later SVM and Logistic regression fitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7069767441860465\n"
     ]
    }
   ],
   "source": [
    "#Training using Undersample Method1 \n",
    "for train_indices, test_indices in cv_object.split(X_us,y_us): \n",
    "\n",
    "    X_train = X_us.values[train_indices]\n",
    "    y_train = y_us.values[train_indices]\n",
    "    \n",
    "    X_test = X_us.values[test_indices]\n",
    "    y_test = y_us.values[test_indices]\n",
    "    \n",
    "\n",
    "clfus=RandomForestClassifier(n_estimators=100)\n",
    "clfus.fit(X_train,y_train)\n",
    "y_pred_us=clfus.predict(X_test)\n",
    "\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred_us))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7955947136563877\n"
     ]
    }
   ],
   "source": [
    "#Training using Undersample Method2\n",
    "for train_indices, test_indices in cv_object.split(X_us_maj,y_us_maj): \n",
    "\n",
    "    X_train = X_us_maj.values[train_indices]\n",
    "    y_train = y_us_maj.values[train_indices]\n",
    "    \n",
    "    X_test = X_us_maj.values[test_indices]\n",
    "    y_test = y_us_maj.values[test_indices]\n",
    "    \n",
    "clfusm=RandomForestClassifier(n_estimators=100)\n",
    "clfusm.fit(X_train,y_train)\n",
    "y_pred_usm=clfusm.predict(X_test)\n",
    "    \n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred_usm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8915177447772464\n"
     ]
    }
   ],
   "source": [
    "#Training using Oversample Method\n",
    "for train_indices, test_indices in cv_object.split(X_sm,y_sm): \n",
    "\n",
    "    X_train = X_sm.values[train_indices]\n",
    "    y_train = y_sm.values[train_indices]\n",
    "    \n",
    "    X_test = X_sm.values[test_indices]\n",
    "    y_test = y_sm.values[test_indices]\n",
    "\n",
    "clfsm=RandomForestClassifier(n_estimators=100)\n",
    "clfsm.fit(X_train,y_train)\n",
    "y_pred_sm=clfsm.predict(X_test)\n",
    "\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred_sm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "[CV] C=0.1, penalty=l1, solver=liblinear .............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .............. C=0.1, penalty=l1, solver=liblinear, total=   3.1s\n",
      "[CV] C=0.1, penalty=l1, solver=liblinear .............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    3.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .............. C=0.1, penalty=l1, solver=liblinear, total=   3.6s\n",
      "[CV] C=0.1, penalty=l1, solver=liblinear .............................\n",
      "[CV] .............. C=0.1, penalty=l1, solver=liblinear, total=   3.7s\n",
      "[CV] C=0.1, penalty=l1, solver=liblinear .............................\n",
      "[CV] .............. C=0.1, penalty=l1, solver=liblinear, total=   3.9s\n",
      "[CV] C=0.1, penalty=l1, solver=liblinear .............................\n",
      "[CV] .............. C=0.1, penalty=l1, solver=liblinear, total=   3.5s\n",
      "[CV] C=0.1, penalty=l1, solver=lbfgs .................................\n",
      "[CV] .................. C=0.1, penalty=l1, solver=lbfgs, total=   0.0s\n",
      "[CV] C=0.1, penalty=l1, solver=lbfgs .................................\n",
      "[CV] .................. C=0.1, penalty=l1, solver=lbfgs, total=   0.0s\n",
      "[CV] C=0.1, penalty=l1, solver=lbfgs .................................\n",
      "[CV] .................. C=0.1, penalty=l1, solver=lbfgs, total=   0.0s\n",
      "[CV] C=0.1, penalty=l1, solver=lbfgs .................................\n",
      "[CV] .................. C=0.1, penalty=l1, solver=lbfgs, total=   0.0s\n",
      "[CV] C=0.1, penalty=l1, solver=lbfgs .................................\n",
      "[CV] .................. C=0.1, penalty=l1, solver=lbfgs, total=   0.0s\n",
      "[CV] C=0.1, penalty=l2, solver=liblinear .............................\n",
      "[CV] .............. C=0.1, penalty=l2, solver=liblinear, total=   3.3s\n",
      "[CV] C=0.1, penalty=l2, solver=liblinear .............................\n",
      "[CV] .............. C=0.1, penalty=l2, solver=liblinear, total=   3.3s\n",
      "[CV] C=0.1, penalty=l2, solver=liblinear .............................\n",
      "[CV] .............. C=0.1, penalty=l2, solver=liblinear, total=   3.4s\n",
      "[CV] C=0.1, penalty=l2, solver=liblinear .............................\n",
      "[CV] .............. C=0.1, penalty=l2, solver=liblinear, total=   3.7s\n",
      "[CV] C=0.1, penalty=l2, solver=liblinear .............................\n",
      "[CV] .............. C=0.1, penalty=l2, solver=liblinear, total=   2.9s\n",
      "[CV] C=0.1, penalty=l2, solver=lbfgs .................................\n",
      "[CV] .................. C=0.1, penalty=l2, solver=lbfgs, total=   0.5s\n",
      "[CV] C=0.1, penalty=l2, solver=lbfgs .................................\n",
      "[CV] .................. C=0.1, penalty=l2, solver=lbfgs, total=   0.5s\n",
      "[CV] C=0.1, penalty=l2, solver=lbfgs .................................\n",
      "[CV] .................. C=0.1, penalty=l2, solver=lbfgs, total=   0.6s\n",
      "[CV] C=0.1, penalty=l2, solver=lbfgs .................................\n",
      "[CV] .................. C=0.1, penalty=l2, solver=lbfgs, total=   0.6s\n",
      "[CV] C=0.1, penalty=l2, solver=lbfgs .................................\n",
      "[CV] .................. C=0.1, penalty=l2, solver=lbfgs, total=   0.7s\n",
      "[CV] C=10, penalty=l1, solver=liblinear ..............................\n",
      "[CV] ............... C=10, penalty=l1, solver=liblinear, total=  17.9s\n",
      "[CV] C=10, penalty=l1, solver=liblinear ..............................\n",
      "[CV] ............... C=10, penalty=l1, solver=liblinear, total=  12.8s\n",
      "[CV] C=10, penalty=l1, solver=liblinear ..............................\n",
      "[CV] ............... C=10, penalty=l1, solver=liblinear, total=  17.6s\n",
      "[CV] C=10, penalty=l1, solver=liblinear ..............................\n",
      "[CV] ............... C=10, penalty=l1, solver=liblinear, total=  22.1s\n",
      "[CV] C=10, penalty=l1, solver=liblinear ..............................\n",
      "[CV] ............... C=10, penalty=l1, solver=liblinear, total=  16.9s\n",
      "[CV] C=10, penalty=l1, solver=lbfgs ..................................\n",
      "[CV] ................... C=10, penalty=l1, solver=lbfgs, total=   0.0s\n",
      "[CV] C=10, penalty=l1, solver=lbfgs ..................................\n",
      "[CV] ................... C=10, penalty=l1, solver=lbfgs, total=   0.0s\n",
      "[CV] C=10, penalty=l1, solver=lbfgs ..................................\n",
      "[CV] ................... C=10, penalty=l1, solver=lbfgs, total=   0.0s\n",
      "[CV] C=10, penalty=l1, solver=lbfgs ..................................\n",
      "[CV] ................... C=10, penalty=l1, solver=lbfgs, total=   0.0s\n",
      "[CV] C=10, penalty=l1, solver=lbfgs ..................................\n",
      "[CV] ................... C=10, penalty=l1, solver=lbfgs, total=   0.0s\n",
      "[CV] C=10, penalty=l2, solver=liblinear ..............................\n",
      "[CV] ............... C=10, penalty=l2, solver=liblinear, total=   3.5s\n",
      "[CV] C=10, penalty=l2, solver=liblinear ..............................\n",
      "[CV] ............... C=10, penalty=l2, solver=liblinear, total=   4.1s\n",
      "[CV] C=10, penalty=l2, solver=liblinear ..............................\n",
      "[CV] ............... C=10, penalty=l2, solver=liblinear, total=   3.4s\n",
      "[CV] C=10, penalty=l2, solver=liblinear ..............................\n",
      "[CV] ............... C=10, penalty=l2, solver=liblinear, total=   3.6s\n",
      "[CV] C=10, penalty=l2, solver=liblinear ..............................\n",
      "[CV] ............... C=10, penalty=l2, solver=liblinear, total=   3.5s\n",
      "[CV] C=10, penalty=l2, solver=lbfgs ..................................\n",
      "[CV] ................... C=10, penalty=l2, solver=lbfgs, total=   0.5s\n",
      "[CV] C=10, penalty=l2, solver=lbfgs ..................................\n",
      "[CV] ................... C=10, penalty=l2, solver=lbfgs, total=   0.5s\n",
      "[CV] C=10, penalty=l2, solver=lbfgs ..................................\n",
      "[CV] ................... C=10, penalty=l2, solver=lbfgs, total=   0.6s\n",
      "[CV] C=10, penalty=l2, solver=lbfgs ..................................\n",
      "[CV] ................... C=10, penalty=l2, solver=lbfgs, total=   0.7s\n",
      "[CV] C=10, penalty=l2, solver=lbfgs ..................................\n",
      "[CV] ................... C=10, penalty=l2, solver=lbfgs, total=   0.7s\n",
      "[CV] C=100, penalty=l1, solver=liblinear .............................\n",
      "[CV] .............. C=100, penalty=l1, solver=liblinear, total=  15.7s\n",
      "[CV] C=100, penalty=l1, solver=liblinear .............................\n",
      "[CV] .............. C=100, penalty=l1, solver=liblinear, total=  14.1s\n",
      "[CV] C=100, penalty=l1, solver=liblinear .............................\n",
      "[CV] .............. C=100, penalty=l1, solver=liblinear, total=  10.5s\n",
      "[CV] C=100, penalty=l1, solver=liblinear .............................\n",
      "[CV] .............. C=100, penalty=l1, solver=liblinear, total=  18.3s\n",
      "[CV] C=100, penalty=l1, solver=liblinear .............................\n",
      "[CV] .............. C=100, penalty=l1, solver=liblinear, total=  21.0s\n",
      "[CV] C=100, penalty=l1, solver=lbfgs .................................\n",
      "[CV] .................. C=100, penalty=l1, solver=lbfgs, total=   0.0s\n",
      "[CV] C=100, penalty=l1, solver=lbfgs .................................\n",
      "[CV] .................. C=100, penalty=l1, solver=lbfgs, total=   0.0s\n",
      "[CV] C=100, penalty=l1, solver=lbfgs .................................\n",
      "[CV] .................. C=100, penalty=l1, solver=lbfgs, total=   0.0s\n",
      "[CV] C=100, penalty=l1, solver=lbfgs .................................\n",
      "[CV] .................. C=100, penalty=l1, solver=lbfgs, total=   0.0s\n",
      "[CV] C=100, penalty=l1, solver=lbfgs .................................\n",
      "[CV] .................. C=100, penalty=l1, solver=lbfgs, total=   0.0s\n",
      "[CV] C=100, penalty=l2, solver=liblinear .............................\n",
      "[CV] .............. C=100, penalty=l2, solver=liblinear, total=   3.3s\n",
      "[CV] C=100, penalty=l2, solver=liblinear .............................\n",
      "[CV] .............. C=100, penalty=l2, solver=liblinear, total=   3.9s\n",
      "[CV] C=100, penalty=l2, solver=liblinear .............................\n",
      "[CV] .............. C=100, penalty=l2, solver=liblinear, total=   3.8s\n",
      "[CV] C=100, penalty=l2, solver=liblinear .............................\n",
      "[CV] .............. C=100, penalty=l2, solver=liblinear, total=   3.7s\n",
      "[CV] C=100, penalty=l2, solver=liblinear .............................\n",
      "[CV] .............. C=100, penalty=l2, solver=liblinear, total=   3.4s\n",
      "[CV] C=100, penalty=l2, solver=lbfgs .................................\n",
      "[CV] .................. C=100, penalty=l2, solver=lbfgs, total=   0.5s\n",
      "[CV] C=100, penalty=l2, solver=lbfgs .................................\n",
      "[CV] .................. C=100, penalty=l2, solver=lbfgs, total=   0.5s\n",
      "[CV] C=100, penalty=l2, solver=lbfgs .................................\n",
      "[CV] .................. C=100, penalty=l2, solver=lbfgs, total=   0.6s\n",
      "[CV] C=100, penalty=l2, solver=lbfgs .................................\n",
      "[CV] .................. C=100, penalty=l2, solver=lbfgs, total=   0.6s\n",
      "[CV] C=100, penalty=l2, solver=lbfgs .................................\n",
      "[CV] .................. C=100, penalty=l2, solver=lbfgs, total=   0.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  60 out of  60 | elapsed:  4.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4min 47s, sys: 10.2 s, total: 4min 58s\n",
      "Wall time: 4min 21s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=LogisticRegression(),\n",
       "             param_grid={'C': [0.1, 10, 100], 'penalty': ['l1', 'l2'],\n",
       "                         'solver': ['liblinear', 'lbfgs']},\n",
       "             verbose=2)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "param_grid = {'C': [0.1, 10, 100], 'penalty': ['l1','l2'], 'solver': ['liblinear', 'lbfgs']}\n",
    "\n",
    "grid = GridSearchCV(LogisticRegression(), param_grid, refit=True, verbose=2)\n",
    "grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 10, 'penalty': 'l1', 'solver': 'liblinear'}\n"
     ]
    }
   ],
   "source": [
    "print(grid.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling\n",
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.3574125346086081"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "lr_model = LogisticRegression()\n",
    "\n",
    "lr_model.fit(X_train, y_train)\n",
    "pred = lr_model.predict(X_test)\n",
    "\n",
    "accuracy_score(y_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=10, penalty='l1', solver='liblinear')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.6863830858293481"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Lasso\n",
    "model2 = LogisticRegression(C=10, penalty='l1', solver='liblinear')\n",
    "\n",
    "model2.fit(X_train, y_train)\n",
    "pred = model2.predict(X_test)\n",
    "\n",
    "accuracy_score(y_test, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machine (SVM)\n",
    "First, let's split the original dataset (with No SMOTE balancing) to train/test, and do SVM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split X and Y into Training and Testing dataset\n",
    "for train_indices, test_indices in cv_object.split(schoolData_pick_new,schoolData_SPG_new): \n",
    "\n",
    "    Xsel_train = schoolData_pick_new.values[train_indices]\n",
    "    ysel_train = schoolData_SPG_new[train_indices]\n",
    "    \n",
    "    Xsel_test = schoolData_pick_new.values[test_indices]\n",
    "    ysel_test = schoolData_SPG_new[test_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "scl_obj = StandardScaler()\n",
    "\n",
    "Xorg_train_scaled = scl_obj.fit_transform(Xsel_train) # apply to training\n",
    "Xorg_test_scaled = scl_obj.fit_transform(Xsel_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# lets investigate SVMs on the data and play with the parameters and kernels\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import metrics as mt\n",
    "\n",
    "# train the model just as before\n",
    "svm_clf = SVC(C=0.5, kernel='rbf', degree=3, gamma='auto') # get object\n",
    "svm_clf.fit(Xorg_train_scaled, ysel_train)  # train object\n",
    "\n",
    "y_hat = svm_clf.predict(Xorg_test_scaled) # get test set precitions\n",
    "\n",
    "acc = mt.accuracy_score(ysel_test,y_hat)\n",
    "conf = mt.confusion_matrix(ysel_test,y_hat)\n",
    "print('accuracy:', acc )\n",
    "print(conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = plt.figure(figsize=(8,8))\n",
    "plt.imshow(conf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy for the above model is around 70%. However the confusion matrix shows that because the data is imbalance, the accuracy across different class are a lot different from each other. For example, the accuracy rate of C is much higher than other class.\n",
    "\n",
    "Below we are using the SMOTE balanced dataset for SVM work:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "scl_obj = StandardScaler()\n",
    "\n",
    "Xs2_train_scaled = scl_obj.fit_transform(X_train) # apply to training\n",
    "Xs2_test_scaled = scl_obj.fit_transform(X_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.8273345079285175\n",
      "[[759  51   3   0   0]\n",
      " [ 59 608 110   8   0]\n",
      " [  4 115 529 108   4]\n",
      " [  0   3 104 636  77]\n",
      " [  0   0   3  37 755]]\n",
      "CPU times: user 14.2 s, sys: 266 ms, total: 14.4 s\n",
      "Wall time: 14.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# lets investigate SVMs on the data and play with the parameters and kernels\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import metrics as mt\n",
    "\n",
    "# train the model just as before\n",
    "svm_clf = SVC(C=0.5, kernel='rbf', degree=3, gamma='auto') # get object\n",
    "svm_clf.fit(Xs2_train_scaled, y_train)  # train object\n",
    "\n",
    "y_hat = svm_clf.predict(Xs2_test_scaled) # get test set precitions\n",
    "\n",
    "acc = mt.accuracy_score(y_test,y_hat)\n",
    "conf = mt.confusion_matrix(y_test,y_hat)\n",
    "print('accuracy:', acc )\n",
    "print(conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x143dd0b10>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "f = plt.figure(figsize=(8,8))\n",
    "plt.imshow(conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10674, 50)\n",
      "(10674,)\n",
      "[1265 2527 2800 2649 1433]\n"
     ]
    }
   ],
   "source": [
    "# look at the support vectors\n",
    "print(svm_clf.support_vectors_.shape)\n",
    "print(svm_clf.support_.shape)\n",
    "print(svm_clf.n_support_ )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 32 candidates, totalling 160 fits\n",
      "[CV] C=0.1, gamma=1, kernel=rbf ......................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ....................... C=0.1, gamma=1, kernel=rbf, total=  29.1s\n",
      "[CV] C=0.1, gamma=1, kernel=rbf ......................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   29.2s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ....................... C=0.1, gamma=1, kernel=rbf, total=  29.3s\n",
      "[CV] C=0.1, gamma=1, kernel=rbf ......................................\n",
      "[CV] ....................... C=0.1, gamma=1, kernel=rbf, total=  27.4s\n",
      "[CV] C=0.1, gamma=1, kernel=rbf ......................................\n",
      "[CV] ....................... C=0.1, gamma=1, kernel=rbf, total=  27.1s\n",
      "[CV] C=0.1, gamma=1, kernel=rbf ......................................\n",
      "[CV] ....................... C=0.1, gamma=1, kernel=rbf, total=  27.5s\n",
      "[CV] C=0.1, gamma=1, kernel=sigmoid ..................................\n",
      "[CV] ................... C=0.1, gamma=1, kernel=sigmoid, total=  12.7s\n",
      "[CV] C=0.1, gamma=1, kernel=sigmoid ..................................\n",
      "[CV] ................... C=0.1, gamma=1, kernel=sigmoid, total=  12.8s\n",
      "[CV] C=0.1, gamma=1, kernel=sigmoid ..................................\n",
      "[CV] ................... C=0.1, gamma=1, kernel=sigmoid, total=  12.9s\n",
      "[CV] C=0.1, gamma=1, kernel=sigmoid ..................................\n",
      "[CV] ................... C=0.1, gamma=1, kernel=sigmoid, total=  12.6s\n",
      "[CV] C=0.1, gamma=1, kernel=sigmoid ..................................\n",
      "[CV] ................... C=0.1, gamma=1, kernel=sigmoid, total=  14.2s\n",
      "[CV] C=0.1, gamma=0.1, kernel=rbf ....................................\n",
      "[CV] ..................... C=0.1, gamma=0.1, kernel=rbf, total=  22.3s\n",
      "[CV] C=0.1, gamma=0.1, kernel=rbf ....................................\n",
      "[CV] ..................... C=0.1, gamma=0.1, kernel=rbf, total=  23.1s\n",
      "[CV] C=0.1, gamma=0.1, kernel=rbf ....................................\n",
      "[CV] ..................... C=0.1, gamma=0.1, kernel=rbf, total=  22.7s\n",
      "[CV] C=0.1, gamma=0.1, kernel=rbf ....................................\n",
      "[CV] ..................... C=0.1, gamma=0.1, kernel=rbf, total=  23.7s\n",
      "[CV] C=0.1, gamma=0.1, kernel=rbf ....................................\n",
      "[CV] ..................... C=0.1, gamma=0.1, kernel=rbf, total=  23.6s\n",
      "[CV] C=0.1, gamma=0.1, kernel=sigmoid ................................\n",
      "[CV] ................. C=0.1, gamma=0.1, kernel=sigmoid, total=  13.0s\n",
      "[CV] C=0.1, gamma=0.1, kernel=sigmoid ................................\n",
      "[CV] ................. C=0.1, gamma=0.1, kernel=sigmoid, total=  13.9s\n",
      "[CV] C=0.1, gamma=0.1, kernel=sigmoid ................................\n",
      "[CV] ................. C=0.1, gamma=0.1, kernel=sigmoid, total=  13.3s\n",
      "[CV] C=0.1, gamma=0.1, kernel=sigmoid ................................\n",
      "[CV] ................. C=0.1, gamma=0.1, kernel=sigmoid, total=  13.0s\n",
      "[CV] C=0.1, gamma=0.1, kernel=sigmoid ................................\n",
      "[CV] ................. C=0.1, gamma=0.1, kernel=sigmoid, total=  13.0s\n",
      "[CV] C=0.1, gamma=0.01, kernel=rbf ...................................\n",
      "[CV] .................... C=0.1, gamma=0.01, kernel=rbf, total=  12.3s\n",
      "[CV] C=0.1, gamma=0.01, kernel=rbf ...................................\n",
      "[CV] .................... C=0.1, gamma=0.01, kernel=rbf, total=  12.6s\n",
      "[CV] C=0.1, gamma=0.01, kernel=rbf ...................................\n",
      "[CV] .................... C=0.1, gamma=0.01, kernel=rbf, total=  12.2s\n",
      "[CV] C=0.1, gamma=0.01, kernel=rbf ...................................\n",
      "[CV] .................... C=0.1, gamma=0.01, kernel=rbf, total=  12.2s\n",
      "[CV] C=0.1, gamma=0.01, kernel=rbf ...................................\n",
      "[CV] .................... C=0.1, gamma=0.01, kernel=rbf, total=  12.2s\n",
      "[CV] C=0.1, gamma=0.01, kernel=sigmoid ...............................\n",
      "[CV] ................ C=0.1, gamma=0.01, kernel=sigmoid, total=  13.4s\n",
      "[CV] C=0.1, gamma=0.01, kernel=sigmoid ...............................\n",
      "[CV] ................ C=0.1, gamma=0.01, kernel=sigmoid, total=  14.8s\n",
      "[CV] C=0.1, gamma=0.01, kernel=sigmoid ...............................\n",
      "[CV] ................ C=0.1, gamma=0.01, kernel=sigmoid, total=  16.8s\n",
      "[CV] C=0.1, gamma=0.01, kernel=sigmoid ...............................\n",
      "[CV] ................ C=0.1, gamma=0.01, kernel=sigmoid, total=  16.4s\n",
      "[CV] C=0.1, gamma=0.01, kernel=sigmoid ...............................\n",
      "[CV] ................ C=0.1, gamma=0.01, kernel=sigmoid, total=  15.7s\n",
      "[CV] C=0.1, gamma=0.001, kernel=rbf ..................................\n",
      "[CV] ................... C=0.1, gamma=0.001, kernel=rbf, total=  23.4s\n",
      "[CV] C=0.1, gamma=0.001, kernel=rbf ..................................\n",
      "[CV] ................... C=0.1, gamma=0.001, kernel=rbf, total=  19.1s\n",
      "[CV] C=0.1, gamma=0.001, kernel=rbf ..................................\n",
      "[CV] ................... C=0.1, gamma=0.001, kernel=rbf, total=  21.8s\n",
      "[CV] C=0.1, gamma=0.001, kernel=rbf ..................................\n",
      "[CV] ................... C=0.1, gamma=0.001, kernel=rbf, total=  21.1s\n",
      "[CV] C=0.1, gamma=0.001, kernel=rbf ..................................\n",
      "[CV] ................... C=0.1, gamma=0.001, kernel=rbf, total=  20.4s\n",
      "[CV] C=0.1, gamma=0.001, kernel=sigmoid ..............................\n",
      "[CV] ............... C=0.1, gamma=0.001, kernel=sigmoid, total=  20.8s\n",
      "[CV] C=0.1, gamma=0.001, kernel=sigmoid ..............................\n",
      "[CV] ............... C=0.1, gamma=0.001, kernel=sigmoid, total=  20.5s\n",
      "[CV] C=0.1, gamma=0.001, kernel=sigmoid ..............................\n",
      "[CV] ............... C=0.1, gamma=0.001, kernel=sigmoid, total=  20.2s\n",
      "[CV] C=0.1, gamma=0.001, kernel=sigmoid ..............................\n",
      "[CV] ............... C=0.1, gamma=0.001, kernel=sigmoid, total=  20.6s\n",
      "[CV] C=0.1, gamma=0.001, kernel=sigmoid ..............................\n",
      "[CV] ............... C=0.1, gamma=0.001, kernel=sigmoid, total=  19.8s\n",
      "[CV] C=1, gamma=1, kernel=rbf ........................................\n",
      "[CV] ......................... C=1, gamma=1, kernel=rbf, total=  33.9s\n",
      "[CV] C=1, gamma=1, kernel=rbf ........................................\n",
      "[CV] ......................... C=1, gamma=1, kernel=rbf, total=  34.0s\n",
      "[CV] C=1, gamma=1, kernel=rbf ........................................\n",
      "[CV] ......................... C=1, gamma=1, kernel=rbf, total=  33.8s\n",
      "[CV] C=1, gamma=1, kernel=rbf ........................................\n",
      "[CV] ......................... C=1, gamma=1, kernel=rbf, total=  29.8s\n",
      "[CV] C=1, gamma=1, kernel=rbf ........................................\n",
      "[CV] ......................... C=1, gamma=1, kernel=rbf, total=  31.1s\n",
      "[CV] C=1, gamma=1, kernel=sigmoid ....................................\n",
      "[CV] ..................... C=1, gamma=1, kernel=sigmoid, total=  13.8s\n",
      "[CV] C=1, gamma=1, kernel=sigmoid ....................................\n",
      "[CV] ..................... C=1, gamma=1, kernel=sigmoid, total=  11.9s\n",
      "[CV] C=1, gamma=1, kernel=sigmoid ....................................\n",
      "[CV] ..................... C=1, gamma=1, kernel=sigmoid, total=  11.9s\n",
      "[CV] C=1, gamma=1, kernel=sigmoid ....................................\n",
      "[CV] ..................... C=1, gamma=1, kernel=sigmoid, total=  12.5s\n",
      "[CV] C=1, gamma=1, kernel=sigmoid ....................................\n",
      "[CV] ..................... C=1, gamma=1, kernel=sigmoid, total=  12.7s\n",
      "[CV] C=1, gamma=0.1, kernel=rbf ......................................\n",
      "[CV] ....................... C=1, gamma=0.1, kernel=rbf, total=  18.2s\n",
      "[CV] C=1, gamma=0.1, kernel=rbf ......................................\n",
      "[CV] ....................... C=1, gamma=0.1, kernel=rbf, total=  19.9s\n",
      "[CV] C=1, gamma=0.1, kernel=rbf ......................................\n",
      "[CV] ....................... C=1, gamma=0.1, kernel=rbf, total=  20.0s\n",
      "[CV] C=1, gamma=0.1, kernel=rbf ......................................\n",
      "[CV] ....................... C=1, gamma=0.1, kernel=rbf, total=  18.6s\n",
      "[CV] C=1, gamma=0.1, kernel=rbf ......................................\n",
      "[CV] ....................... C=1, gamma=0.1, kernel=rbf, total=  18.3s\n",
      "[CV] C=1, gamma=0.1, kernel=sigmoid ..................................\n",
      "[CV] ................... C=1, gamma=0.1, kernel=sigmoid, total=  12.1s\n",
      "[CV] C=1, gamma=0.1, kernel=sigmoid ..................................\n",
      "[CV] ................... C=1, gamma=0.1, kernel=sigmoid, total=  13.6s\n",
      "[CV] C=1, gamma=0.1, kernel=sigmoid ..................................\n",
      "[CV] ................... C=1, gamma=0.1, kernel=sigmoid, total=  12.4s\n",
      "[CV] C=1, gamma=0.1, kernel=sigmoid ..................................\n",
      "[CV] ................... C=1, gamma=0.1, kernel=sigmoid, total=  14.0s\n",
      "[CV] C=1, gamma=0.1, kernel=sigmoid ..................................\n",
      "[CV] ................... C=1, gamma=0.1, kernel=sigmoid, total=  15.3s\n",
      "[CV] C=1, gamma=0.01, kernel=rbf .....................................\n",
      "[CV] ...................... C=1, gamma=0.01, kernel=rbf, total=   9.0s\n",
      "[CV] C=1, gamma=0.01, kernel=rbf .....................................\n",
      "[CV] ...................... C=1, gamma=0.01, kernel=rbf, total=   9.1s\n",
      "[CV] C=1, gamma=0.01, kernel=rbf .....................................\n",
      "[CV] ...................... C=1, gamma=0.01, kernel=rbf, total=   9.1s\n",
      "[CV] C=1, gamma=0.01, kernel=rbf .....................................\n",
      "[CV] ...................... C=1, gamma=0.01, kernel=rbf, total=   9.0s\n",
      "[CV] C=1, gamma=0.01, kernel=rbf .....................................\n",
      "[CV] ...................... C=1, gamma=0.01, kernel=rbf, total=   8.8s\n",
      "[CV] C=1, gamma=0.01, kernel=sigmoid .................................\n",
      "[CV] .................. C=1, gamma=0.01, kernel=sigmoid, total=   8.7s\n",
      "[CV] C=1, gamma=0.01, kernel=sigmoid .................................\n",
      "[CV] .................. C=1, gamma=0.01, kernel=sigmoid, total=   8.2s\n",
      "[CV] C=1, gamma=0.01, kernel=sigmoid .................................\n",
      "[CV] .................. C=1, gamma=0.01, kernel=sigmoid, total=   8.9s\n",
      "[CV] C=1, gamma=0.01, kernel=sigmoid .................................\n",
      "[CV] .................. C=1, gamma=0.01, kernel=sigmoid, total=   8.8s\n",
      "[CV] C=1, gamma=0.01, kernel=sigmoid .................................\n",
      "[CV] .................. C=1, gamma=0.01, kernel=sigmoid, total=   9.2s\n",
      "[CV] C=1, gamma=0.001, kernel=rbf ....................................\n",
      "[CV] ..................... C=1, gamma=0.001, kernel=rbf, total=  12.0s\n",
      "[CV] C=1, gamma=0.001, kernel=rbf ....................................\n",
      "[CV] ..................... C=1, gamma=0.001, kernel=rbf, total=  11.9s\n",
      "[CV] C=1, gamma=0.001, kernel=rbf ....................................\n",
      "[CV] ..................... C=1, gamma=0.001, kernel=rbf, total=  11.9s\n",
      "[CV] C=1, gamma=0.001, kernel=rbf ....................................\n",
      "[CV] ..................... C=1, gamma=0.001, kernel=rbf, total=  12.0s\n",
      "[CV] C=1, gamma=0.001, kernel=rbf ....................................\n",
      "[CV] ..................... C=1, gamma=0.001, kernel=rbf, total=  13.5s\n",
      "[CV] C=1, gamma=0.001, kernel=sigmoid ................................\n",
      "[CV] ................. C=1, gamma=0.001, kernel=sigmoid, total=  12.7s\n",
      "[CV] C=1, gamma=0.001, kernel=sigmoid ................................\n",
      "[CV] ................. C=1, gamma=0.001, kernel=sigmoid, total=  13.0s\n",
      "[CV] C=1, gamma=0.001, kernel=sigmoid ................................\n",
      "[CV] ................. C=1, gamma=0.001, kernel=sigmoid, total=  12.9s\n",
      "[CV] C=1, gamma=0.001, kernel=sigmoid ................................\n",
      "[CV] ................. C=1, gamma=0.001, kernel=sigmoid, total=  13.1s\n",
      "[CV] C=1, gamma=0.001, kernel=sigmoid ................................\n",
      "[CV] ................. C=1, gamma=0.001, kernel=sigmoid, total=  12.8s\n",
      "[CV] C=10, gamma=1, kernel=rbf .......................................\n",
      "[CV] ........................ C=10, gamma=1, kernel=rbf, total=  34.9s\n",
      "[CV] C=10, gamma=1, kernel=rbf .......................................\n",
      "[CV] ........................ C=10, gamma=1, kernel=rbf, total=  35.1s\n",
      "[CV] C=10, gamma=1, kernel=rbf .......................................\n",
      "[CV] ........................ C=10, gamma=1, kernel=rbf, total=  34.9s\n",
      "[CV] C=10, gamma=1, kernel=rbf .......................................\n",
      "[CV] ........................ C=10, gamma=1, kernel=rbf, total=  33.2s\n",
      "[CV] C=10, gamma=1, kernel=rbf .......................................\n",
      "[CV] ........................ C=10, gamma=1, kernel=rbf, total=  30.2s\n",
      "[CV] C=10, gamma=1, kernel=sigmoid ...................................\n",
      "[CV] .................... C=10, gamma=1, kernel=sigmoid, total=  12.4s\n",
      "[CV] C=10, gamma=1, kernel=sigmoid ...................................\n",
      "[CV] .................... C=10, gamma=1, kernel=sigmoid, total=  11.7s\n",
      "[CV] C=10, gamma=1, kernel=sigmoid ...................................\n",
      "[CV] .................... C=10, gamma=1, kernel=sigmoid, total=  11.9s\n",
      "[CV] C=10, gamma=1, kernel=sigmoid ...................................\n",
      "[CV] .................... C=10, gamma=1, kernel=sigmoid, total=  12.0s\n",
      "[CV] C=10, gamma=1, kernel=sigmoid ...................................\n",
      "[CV] .................... C=10, gamma=1, kernel=sigmoid, total=  13.1s\n",
      "[CV] C=10, gamma=0.1, kernel=rbf .....................................\n",
      "[CV] ...................... C=10, gamma=0.1, kernel=rbf, total=  21.7s\n",
      "[CV] C=10, gamma=0.1, kernel=rbf .....................................\n",
      "[CV] ...................... C=10, gamma=0.1, kernel=rbf, total=  20.0s\n",
      "[CV] C=10, gamma=0.1, kernel=rbf .....................................\n",
      "[CV] ...................... C=10, gamma=0.1, kernel=rbf, total=  19.6s\n",
      "[CV] C=10, gamma=0.1, kernel=rbf .....................................\n",
      "[CV] ...................... C=10, gamma=0.1, kernel=rbf, total=  20.1s\n",
      "[CV] C=10, gamma=0.1, kernel=rbf .....................................\n",
      "[CV] ...................... C=10, gamma=0.1, kernel=rbf, total=  19.2s\n",
      "[CV] C=10, gamma=0.1, kernel=sigmoid .................................\n",
      "[CV] .................. C=10, gamma=0.1, kernel=sigmoid, total=  10.8s\n",
      "[CV] C=10, gamma=0.1, kernel=sigmoid .................................\n",
      "[CV] .................. C=10, gamma=0.1, kernel=sigmoid, total=  12.0s\n",
      "[CV] C=10, gamma=0.1, kernel=sigmoid .................................\n",
      "[CV] .................. C=10, gamma=0.1, kernel=sigmoid, total=  12.2s\n",
      "[CV] C=10, gamma=0.1, kernel=sigmoid .................................\n",
      "[CV] .................. C=10, gamma=0.1, kernel=sigmoid, total=  12.0s\n",
      "[CV] C=10, gamma=0.1, kernel=sigmoid .................................\n",
      "[CV] .................. C=10, gamma=0.1, kernel=sigmoid, total=  10.7s\n",
      "[CV] C=10, gamma=0.01, kernel=rbf ....................................\n",
      "[CV] ..................... C=10, gamma=0.01, kernel=rbf, total=   7.0s\n",
      "[CV] C=10, gamma=0.01, kernel=rbf ....................................\n",
      "[CV] ..................... C=10, gamma=0.01, kernel=rbf, total=   7.1s\n",
      "[CV] C=10, gamma=0.01, kernel=rbf ....................................\n",
      "[CV] ..................... C=10, gamma=0.01, kernel=rbf, total=   7.3s\n",
      "[CV] C=10, gamma=0.01, kernel=rbf ....................................\n",
      "[CV] ..................... C=10, gamma=0.01, kernel=rbf, total=   7.2s\n",
      "[CV] C=10, gamma=0.01, kernel=rbf ....................................\n",
      "[CV] ..................... C=10, gamma=0.01, kernel=rbf, total=   7.1s\n",
      "[CV] C=10, gamma=0.01, kernel=sigmoid ................................\n",
      "[CV] ................. C=10, gamma=0.01, kernel=sigmoid, total=   5.7s\n",
      "[CV] C=10, gamma=0.01, kernel=sigmoid ................................\n",
      "[CV] ................. C=10, gamma=0.01, kernel=sigmoid, total=   5.6s\n",
      "[CV] C=10, gamma=0.01, kernel=sigmoid ................................\n",
      "[CV] ................. C=10, gamma=0.01, kernel=sigmoid, total=   6.3s\n",
      "[CV] C=10, gamma=0.01, kernel=sigmoid ................................\n",
      "[CV] ................. C=10, gamma=0.01, kernel=sigmoid, total=   5.5s\n",
      "[CV] C=10, gamma=0.01, kernel=sigmoid ................................\n",
      "[CV] ................. C=10, gamma=0.01, kernel=sigmoid, total=   5.9s\n",
      "[CV] C=10, gamma=0.001, kernel=rbf ...................................\n",
      "[CV] .................... C=10, gamma=0.001, kernel=rbf, total=   8.7s\n",
      "[CV] C=10, gamma=0.001, kernel=rbf ...................................\n",
      "[CV] .................... C=10, gamma=0.001, kernel=rbf, total=   8.4s\n",
      "[CV] C=10, gamma=0.001, kernel=rbf ...................................\n",
      "[CV] .................... C=10, gamma=0.001, kernel=rbf, total=   8.6s\n",
      "[CV] C=10, gamma=0.001, kernel=rbf ...................................\n",
      "[CV] .................... C=10, gamma=0.001, kernel=rbf, total=   8.5s\n",
      "[CV] C=10, gamma=0.001, kernel=rbf ...................................\n",
      "[CV] .................... C=10, gamma=0.001, kernel=rbf, total=   8.3s\n",
      "[CV] C=10, gamma=0.001, kernel=sigmoid ...............................\n",
      "[CV] ................ C=10, gamma=0.001, kernel=sigmoid, total=   8.1s\n",
      "[CV] C=10, gamma=0.001, kernel=sigmoid ...............................\n",
      "[CV] ................ C=10, gamma=0.001, kernel=sigmoid, total=   8.0s\n",
      "[CV] C=10, gamma=0.001, kernel=sigmoid ...............................\n",
      "[CV] ................ C=10, gamma=0.001, kernel=sigmoid, total=   8.2s\n",
      "[CV] C=10, gamma=0.001, kernel=sigmoid ...............................\n",
      "[CV] ................ C=10, gamma=0.001, kernel=sigmoid, total=   8.3s\n",
      "[CV] C=10, gamma=0.001, kernel=sigmoid ...............................\n",
      "[CV] ................ C=10, gamma=0.001, kernel=sigmoid, total=   8.1s\n",
      "[CV] C=100, gamma=1, kernel=rbf ......................................\n",
      "[CV] ....................... C=100, gamma=1, kernel=rbf, total=  31.0s\n",
      "[CV] C=100, gamma=1, kernel=rbf ......................................\n",
      "[CV] ....................... C=100, gamma=1, kernel=rbf, total=  31.0s\n",
      "[CV] C=100, gamma=1, kernel=rbf ......................................\n",
      "[CV] ....................... C=100, gamma=1, kernel=rbf, total=  30.4s\n",
      "[CV] C=100, gamma=1, kernel=rbf ......................................\n",
      "[CV] ....................... C=100, gamma=1, kernel=rbf, total=  32.5s\n",
      "[CV] C=100, gamma=1, kernel=rbf ......................................\n",
      "[CV] ....................... C=100, gamma=1, kernel=rbf, total=  33.6s\n",
      "[CV] C=100, gamma=1, kernel=sigmoid ..................................\n",
      "[CV] ................... C=100, gamma=1, kernel=sigmoid, total=  14.6s\n",
      "[CV] C=100, gamma=1, kernel=sigmoid ..................................\n",
      "[CV] ................... C=100, gamma=1, kernel=sigmoid, total=  13.1s\n",
      "[CV] C=100, gamma=1, kernel=sigmoid ..................................\n",
      "[CV] ................... C=100, gamma=1, kernel=sigmoid, total=  13.4s\n",
      "[CV] C=100, gamma=1, kernel=sigmoid ..................................\n",
      "[CV] ................... C=100, gamma=1, kernel=sigmoid, total=  13.5s\n",
      "[CV] C=100, gamma=1, kernel=sigmoid ..................................\n",
      "[CV] ................... C=100, gamma=1, kernel=sigmoid, total=  13.3s\n",
      "[CV] C=100, gamma=0.1, kernel=rbf ....................................\n",
      "[CV] ..................... C=100, gamma=0.1, kernel=rbf, total=  22.8s\n",
      "[CV] C=100, gamma=0.1, kernel=rbf ....................................\n",
      "[CV] ..................... C=100, gamma=0.1, kernel=rbf, total=  21.9s\n",
      "[CV] C=100, gamma=0.1, kernel=rbf ....................................\n",
      "[CV] ..................... C=100, gamma=0.1, kernel=rbf, total=  21.5s\n",
      "[CV] C=100, gamma=0.1, kernel=rbf ....................................\n",
      "[CV] ..................... C=100, gamma=0.1, kernel=rbf, total=  20.6s\n",
      "[CV] C=100, gamma=0.1, kernel=rbf ....................................\n",
      "[CV] ..................... C=100, gamma=0.1, kernel=rbf, total=  21.7s\n",
      "[CV] C=100, gamma=0.1, kernel=sigmoid ................................\n",
      "[CV] ................. C=100, gamma=0.1, kernel=sigmoid, total=  11.6s\n",
      "[CV] C=100, gamma=0.1, kernel=sigmoid ................................\n",
      "[CV] ................. C=100, gamma=0.1, kernel=sigmoid, total=  12.3s\n",
      "[CV] C=100, gamma=0.1, kernel=sigmoid ................................\n",
      "[CV] ................. C=100, gamma=0.1, kernel=sigmoid, total=  12.2s\n",
      "[CV] C=100, gamma=0.1, kernel=sigmoid ................................\n",
      "[CV] ................. C=100, gamma=0.1, kernel=sigmoid, total=  12.8s\n",
      "[CV] C=100, gamma=0.1, kernel=sigmoid ................................\n",
      "[CV] ................. C=100, gamma=0.1, kernel=sigmoid, total=  12.7s\n",
      "[CV] C=100, gamma=0.01, kernel=rbf ...................................\n",
      "[CV] .................... C=100, gamma=0.01, kernel=rbf, total=   9.6s\n",
      "[CV] C=100, gamma=0.01, kernel=rbf ...................................\n",
      "[CV] .................... C=100, gamma=0.01, kernel=rbf, total=   9.3s\n",
      "[CV] C=100, gamma=0.01, kernel=rbf ...................................\n",
      "[CV] .................... C=100, gamma=0.01, kernel=rbf, total=   9.1s\n",
      "[CV] C=100, gamma=0.01, kernel=rbf ...................................\n",
      "[CV] .................... C=100, gamma=0.01, kernel=rbf, total=   9.9s\n",
      "[CV] C=100, gamma=0.01, kernel=rbf ...................................\n",
      "[CV] .................... C=100, gamma=0.01, kernel=rbf, total=   9.7s\n",
      "[CV] C=100, gamma=0.01, kernel=sigmoid ...............................\n",
      "[CV] ................ C=100, gamma=0.01, kernel=sigmoid, total=   6.2s\n",
      "[CV] C=100, gamma=0.01, kernel=sigmoid ...............................\n",
      "[CV] ................ C=100, gamma=0.01, kernel=sigmoid, total=   6.1s\n",
      "[CV] C=100, gamma=0.01, kernel=sigmoid ...............................\n",
      "[CV] ................ C=100, gamma=0.01, kernel=sigmoid, total=   6.3s\n",
      "[CV] C=100, gamma=0.01, kernel=sigmoid ...............................\n",
      "[CV] ................ C=100, gamma=0.01, kernel=sigmoid, total=   5.8s\n",
      "[CV] C=100, gamma=0.01, kernel=sigmoid ...............................\n",
      "[CV] ................ C=100, gamma=0.01, kernel=sigmoid, total=   5.7s\n",
      "[CV] C=100, gamma=0.001, kernel=rbf ..................................\n",
      "[CV] ................... C=100, gamma=0.001, kernel=rbf, total=   8.8s\n",
      "[CV] C=100, gamma=0.001, kernel=rbf ..................................\n",
      "[CV] ................... C=100, gamma=0.001, kernel=rbf, total=   8.6s\n",
      "[CV] C=100, gamma=0.001, kernel=rbf ..................................\n",
      "[CV] ................... C=100, gamma=0.001, kernel=rbf, total=   8.9s\n",
      "[CV] C=100, gamma=0.001, kernel=rbf ..................................\n",
      "[CV] ................... C=100, gamma=0.001, kernel=rbf, total=   8.9s\n",
      "[CV] C=100, gamma=0.001, kernel=rbf ..................................\n",
      "[CV] ................... C=100, gamma=0.001, kernel=rbf, total=   8.7s\n",
      "[CV] C=100, gamma=0.001, kernel=sigmoid ..............................\n",
      "[CV] ............... C=100, gamma=0.001, kernel=sigmoid, total=   8.6s\n",
      "[CV] C=100, gamma=0.001, kernel=sigmoid ..............................\n",
      "[CV] ............... C=100, gamma=0.001, kernel=sigmoid, total=   8.7s\n",
      "[CV] C=100, gamma=0.001, kernel=sigmoid ..............................\n",
      "[CV] ............... C=100, gamma=0.001, kernel=sigmoid, total=   8.7s\n",
      "[CV] C=100, gamma=0.001, kernel=sigmoid ..............................\n",
      "[CV] ............... C=100, gamma=0.001, kernel=sigmoid, total=   8.4s\n",
      "[CV] C=100, gamma=0.001, kernel=sigmoid ..............................\n",
      "[CV] ............... C=100, gamma=0.001, kernel=sigmoid, total=   8.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 160 out of 160 | elapsed: 40.5min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=SVC(),\n",
       "             param_grid={'C': [0.1, 1, 10, 100], 'gamma': [1, 0.1, 0.01, 0.001],\n",
       "                         'kernel': ['rbf', 'sigmoid']},\n",
       "             verbose=2)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {'C': [0.1, 1, 10, 100], 'gamma': [1, 0.1, 0.01, 0.001], \n",
    "             'kernel': ['rbf', 'sigmoid']}\n",
    "\n",
    "grid = GridSearchCV(SVC(), param_grid, refit=True, verbose=2)\n",
    "grid.fit(Xs2_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 10, 'gamma': 0.1, 'kernel': 'rbf'}\n"
     ]
    }
   ],
   "source": [
    "print(grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9013340045305814\n"
     ]
    }
   ],
   "source": [
    "grid_predictions = grid.predict(Xs2_test_scaled)\n",
    "\n",
    "acc = mt.accuracy_score(y_test, grid_predictions)\n",
    "\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*********\n",
    "****I am re-assigning colnames for plotting, let me know if you have a better way to do that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "schoolData_sm = pd.DataFrame(X_sm)\n",
    "schoolData_sm.columns=['TotalTargets_pTarget_PctMet',\n",
    "'EVAAS Growth Status_NotMet',\n",
    "'MinorityMalePct',\n",
    "'MinorityFemalePct',\n",
    "'title1_type_cd_Y',\n",
    "'avg_daily_attend_pct',\n",
    "'short_susp_per_c_num',\n",
    "'BlackMalePct',\n",
    "'AsianFemalePct',\n",
    "'student_num',\n",
    "'HispanicMalePct',\n",
    "'SciGr5&8_pTarget_PctMet',\n",
    "'tchyrs_0thru3_pct',\n",
    "'tchyrs_11plus_pct',\n",
    "'Accomplished_TCHR_Standard 2_Pct',\n",
    "'Accomplished_TCHR_Standard 1_Pct',\n",
    "'Developing_TCHR_Standard 1_Pct',\n",
    "'Developing_TCHR_Standard 2_Pct',\n",
    "'Developing_TCHR_Standard 3_Pct',\n",
    "'Accomplished_TCHR_Standard 4_Pct',\n",
    "'4-10 Years_LEA_Exp_Pct_Prin',\n",
    "'Developing_TCHR_Standard 4_Pct',\n",
    "'Developing_TCHR_Standard 5_Pct',\n",
    "'10+ Years_LEA_Exp_Pct_Prin',\n",
    "'Accomplished_TCHR_Standard 3_Pct',\n",
    "'Accomplished_TCHR_Standard 5_Pct',\n",
    "'lea_state_perpupil_num',\n",
    "'st_emer_prov_teach_pct',\n",
    "'pct_GCE_ALL',\n",
    "'MathGr3-8_pTarget_PctMet',\n",
    "'lea_sat_avg_score_num',\n",
    "'lea_federal_perpupil_num',\n",
    "'lea_local_perpupil_num',\n",
    "'nbpts_num',\n",
    "'Distinguished_TCHR_Standard 2_Pct',\n",
    "'_1yr_tchr_trnovr_pct',\n",
    "'lateral_teach_pct',\n",
    "'0-3 Years_LEA_Exp_Pct_Prin',\n",
    "'lea_flicensed_teach_pct',\n",
    "'lea_tchyrs_4thru10_pct',\n",
    "'lea_tchyrs_11plus_pct',\n",
    "'lea_nbpts_num',\n",
    "'lea_advance_dgr_pct',\n",
    "'lea_1yr_tchr_trnovr_pct',\n",
    "'lea_emer_prov_teach_pct',\n",
    "'st_flicensed_teach_pct',\n",
    "'st_tchyrs_0thru3_pct',\n",
    "'st_1yr_tchr_trnovr_pct',\n",
    "'lea_tchyrs_0thru3_pct',\n",
    "'Category_Cd_T',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_sm.values[svm_clf.support_] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tested_on = schoolData_sm.iloc[train_indices] # saved from above, the indices chosen for training\n",
    "# now get the support vectors from the trained model\n",
    "df_support = df_tested_on.iloc[svm_clf.support_,:]\n",
    "\n",
    "df_support['SPG Grade'] = y_sm.values[svm_clf.support_] # add back in the 'Survived' Column to the pandas dataframe\n",
    "#X_sub['SPG Grade'] = y # also add it back in for the original data\n",
    "schoolData_sm['SPG Grade'] = y_sm # also add it back in for the original \n",
    "df_support.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now lets see the statistics of these attributes\n",
    "#from pandas.tools.plotting import boxplot\n",
    "from pandas.plotting import boxplot\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# group the original data and the support vectors\n",
    "df_grouped_support = df_support.groupby(['SPG Grade'])\n",
    "#df_grouped = X_sub.groupby(['SPG Grade'])\n",
    "df_grouped = schoolData_sm.groupby(['SPG Grade'])\n",
    "\n",
    "# plot KDE of Different variables\n",
    "###########This is a random selection NOW\n",
    "vars_to_plot = ['tchyrs_0thru3_pct','avg_daily_attend_pct','short_susp_per_c_num','MinorityFemalePct']\n",
    "\n",
    "for v in vars_to_plot:\n",
    "    plt.figure(figsize=(10,4))\n",
    "    # plot support vector stats\n",
    "    plt.subplot(1,2,1)\n",
    "    ax = df_grouped_support[v].plot.kde() \n",
    "    plt.legend(['A','B','C','D','F'])\n",
    "    plt.title(v+' (Instances chosen as Support Vectors)')\n",
    "    \n",
    "    # plot original distributions\n",
    "    plt.subplot(1,2,2)\n",
    "    ax = df_grouped[v].plot.kde() \n",
    "    plt.legend(['A','B','C','D','F'])\n",
    "    plt.title(v+' (Original)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data clean up\n",
    "\n",
    "# schools2['category_cd'].unique()\n",
    "schoolData_sm['category_cd_modified'] = np.select(\n",
    "    [\n",
    "        schoolData_sm['category_cd'] == 'A', \n",
    "        schoolData_sm['category_cd'] == 'E',\n",
    "        schoolData_sm['category_cd'] == 'H',\n",
    "        schoolData_sm['category_cd'] == 'I',\n",
    "        schoolData_sm['category_cd'] == 'M'\n",
    "    ], \n",
    "    [\n",
    "        'Elem./Mid./High Together', \n",
    "        'Elementary School',\n",
    "        'High School',\n",
    "        'Elem./Mid. Together',\n",
    "        'Middle School'\n",
    "    ],\n",
    "    default='Mid./High Together'\n",
    ")\n",
    "\n",
    "combo = schoolData_sm['category_cd_modified'].str.contains('/', regex=False)\n",
    "\n",
    "schoolData_sm['category_cd_modified'] = np.where(combo, 'Combo', schoolData_sm['category_cd_modified'])\n",
    "schoolData_sm['MinorityOverallPct'] = schoolData_sm['MinorityMalePct'] + schoolData_sm['MinorityFemalePct']\n",
    "schoolData_sm['Majority_Minority'] = np.where(schoolData_sm['MinorityOverallPct'] > .5, 1,0)\n",
    "schoolData_sm = schoolData_sm[schoolData_sm[\"school_type_txt\"] == 'Regular School']\n",
    "\n",
    "combo = schoolData_sm['SPG Grade'].str.contains('A+NG', regex=False)\n",
    "\n",
    "schoolData_sm['SPG Grade'] = np.where(combo, 'A', schoolData_sm['SPG Grade'])\n",
    "# df_final['SPG Grade'].value_counts()\n",
    "schoolData_sm = schoolData_sm[schoolData_sm['SPG Grade'] != 'I']\n",
    "schoolData_sm['SPG Grade'].value_counts()\n",
    "schoolData_sm.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "# from sklearn.pipeline import Pipeline\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# from sklearn.feature_selection import \n",
    "\n",
    "# pipe = Pipeline([RandomForestClassifier(n_estimators=)])\n",
    "\n",
    "param_grid = {'C': [0.1, 10, 100], 'penalty': ['l1','l2'], 'solver': ['liblinear']}\n",
    " \n",
    "\n",
    "grid = GridSearchCV(LogisticRegression(), param_grid, refit=True, verbose=2)\n",
    "grid.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
